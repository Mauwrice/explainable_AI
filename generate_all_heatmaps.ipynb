{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate all Heatmaps (Occlusion of GradCam) for a given Version\n",
    "\n",
    "Generates a PDF with all heatmaps for a given version.\n",
    "\n",
    "- Choose heatmap type (Occlusion or GradCam)\n",
    "- Choose if heatmaps should be genereated or loaded\n",
    "- Choose if pictures (mean over all axis, highest heatmap value slice, original image) should be generated or loaded\n",
    "- Choose if all patients should be used or only wrongly classified ones  \n",
    "  \n",
    "\n",
    "  \n",
    "- Define if only the predicted class should be visualized (default: predicted class)\n",
    "- Define if only last gradcam layer should be visualized (default: last layer)\n",
    "\n",
    "## Load Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tqdm\n",
    "# !pip install seaborn\n",
    "# !pip install fpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF  Version 2.2.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc as gci\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "from fpdf import FPDF\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"TF  Version\",tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf\n"
     ]
    }
   ],
   "source": [
    "# check and set path before loading modules\n",
    "print(os.getcwd())\n",
    "INPUT_DIR = \"/tf/notebooks/schnemau/xAI_stroke_3d/\"\n",
    "OUTPUT_DIR = \"/tf/notebooks/schnemau/xAI_stroke_3d/\"\n",
    "if os.getcwd() != OUTPUT_DIR:\n",
    "    os.chdir(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import functions_metrics as fm\n",
    "import functions_read_data as rdat\n",
    "import functions_model_definition as md\n",
    "import functions_gradcam as gc\n",
    "import functions_occlusion as oc\n",
    "import functions_plot_heatmap as phm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/notebooks/schnemau/xAI_stroke_3d\n"
     ]
    }
   ],
   "source": [
    "# Define the path + output path:\n",
    "print(os.getcwd())\n",
    "DATA_DIR = INPUT_DIR + \"data/\"\n",
    "\n",
    "version = \"CIBLSX\" # one of:\n",
    "# 10Fold_sigmoid_V0, 10Fold_sigmoid_V1, 10Fold_sigmoid_V2, 10Fold_sigmoid_V2f, 10Fold_sigmoid_V3\n",
    "# 10Fold_softmax_V0, 10Fold_softmax_V1, andrea\n",
    "# 10Fold_CIB, 10Fold_CIBLSX\n",
    "\n",
    "# Define Outputs of the notebook\n",
    "generate_heatmap_and_save = True # should the heatmap be generated and saved (else loaded)\n",
    "generate_pictures = False # should the pictures be generated (else loaded)\n",
    "only_wrong_out = False # should the generated pdf only contain the wrong predictions (else all)\n",
    "\n",
    "# Define Model Version\n",
    "model_version = 6\n",
    "\n",
    "# define weighting\n",
    "ens_mode = \"wgt\" # avg or wgt => average or weighted heatmap  \n",
    "\n",
    "# define heatmap type\n",
    "hm_type = \"oc\" # gc or oc => gradcam or occlusion\n",
    "norm_hm = True # normalize heatmap (Occlusion is not normalized, gradcam is normalized over all heatmaps)\n",
    "pred_hm_only = True   # if true heatmap of prediction will be generated else positive and negative heatmaps are shown\n",
    "last_layer_only = True # Default = True, only last layer will be used for gradcam else once last and once all layers\n",
    "\n",
    "# Select naming convention (for CIBLSX model_version >= 3 and CIB model_version >= 2 should be False, else True)\n",
    "comp_mode = False # if True: use old naming convention\n",
    "\n",
    "# define paths\n",
    "DATA_DIR, WEIGHT_DIR, DATA_OUTPUT_DIR, PIC_OUTPUT_DIR, pic_save_name = rdat.dir_setup(\n",
    "    INPUT_DIR, OUTPUT_DIR, version, model_version, \n",
    "    weight_mode = ens_mode, hm_type = hm_type, pred_hm = pred_hm_only, hm_norm = norm_hm,\n",
    "    compatibility_mode=comp_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load images and ids\n",
    "(X_in, pat_ids, id_tab, all_results_tab, pat_orig_tab, pat_norm_tab, num_models) = rdat.version_setup(\n",
    "    DATA_DIR = DATA_DIR, version = version, model_version = model_version,\n",
    "    compatibility_mode=comp_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "(input_dim_img, output_dim, LOSS, layer_connection, last_activation) = md.model_setup(version)\n",
    "\n",
    "model_3d = md.model_init(\n",
    "    version = version, \n",
    "    output_dim = output_dim,\n",
    "    LOSS = LOSS,\n",
    "    layer_connection = layer_connection,\n",
    "    last_activation = last_activation,\n",
    "    C = 2,\n",
    "    learning_rate = 5*1e-5,\n",
    "    batch_size = 6,\n",
    "    input_dim = input_dim_img,\n",
    "    input_dim_tab = pat_norm_tab.drop(columns=[\"p_id\"]).shape[1] if \"LSX\" in version else None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mod_ontram'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3d.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model Name\n",
    "generate_model_name = md.set_generate_model_name(\n",
    "    model_version = model_version, \n",
    "    layer_connection = layer_connection, \n",
    "    last_activation = last_activation, \n",
    "    path = WEIGHT_DIR,\n",
    "    compatability_mode=comp_mode)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot GradCams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Heatmap and Heatmap Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all patients\n",
    "p_ids = all_results_tab[\"p_id\"].to_numpy()\n",
    "\n",
    "(res_table, res_images, res_model_names, res_norm_tab) = gc.get_img_and_models(\n",
    "    p_ids, results = all_results_tab, pats = pat_ids, imgs = X_in,\n",
    "    gen_model_name = generate_model_name, norm_tab = pat_norm_tab,\n",
    "    num_models = num_models) # 10 Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>p_idx</th>\n",
       "      <th>p_id</th>\n",
       "      <th>mrs</th>\n",
       "      <th>unfavorable</th>\n",
       "      <th>fold0</th>\n",
       "      <th>fold1</th>\n",
       "      <th>fold2</th>\n",
       "      <th>fold3</th>\n",
       "      <th>fold4</th>\n",
       "      <th>...</th>\n",
       "      <th>threshold_avg</th>\n",
       "      <th>threshold_avg_w</th>\n",
       "      <th>y_pred_class_avg</th>\n",
       "      <th>y_pred_class_avg_w</th>\n",
       "      <th>y_pred_std</th>\n",
       "      <th>y_pred_unc</th>\n",
       "      <th>y_pred_std_w</th>\n",
       "      <th>y_pred_unc_w</th>\n",
       "      <th>pred_correct</th>\n",
       "      <th>pred_correct_w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321884</td>\n",
       "      <td>0.303965</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.000720</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321884</td>\n",
       "      <td>0.303965</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010384</td>\n",
       "      <td>0.028348</td>\n",
       "      <td>0.008630</td>\n",
       "      <td>0.026852</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237775</td>\n",
       "      <td>0.329759</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.060829</td>\n",
       "      <td>0.166263</td>\n",
       "      <td>0.032033</td>\n",
       "      <td>0.099670</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148641</td>\n",
       "      <td>0.134165</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.082791</td>\n",
       "      <td>0.226305</td>\n",
       "      <td>0.028082</td>\n",
       "      <td>0.087377</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>0.424493</td>\n",
       "      <td>0.432574</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009505</td>\n",
       "      <td>0.025944</td>\n",
       "      <td>0.008325</td>\n",
       "      <td>0.025903</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>402</td>\n",
       "      <td>403</td>\n",
       "      <td>555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148641</td>\n",
       "      <td>0.134165</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.035988</td>\n",
       "      <td>0.098349</td>\n",
       "      <td>0.024903</td>\n",
       "      <td>0.077484</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>403</td>\n",
       "      <td>404</td>\n",
       "      <td>556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230867</td>\n",
       "      <td>0.262792</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>404</td>\n",
       "      <td>405</td>\n",
       "      <td>557</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237775</td>\n",
       "      <td>0.329759</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>0.005287</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.001664</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>405</td>\n",
       "      <td>406</td>\n",
       "      <td>559</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>val</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087975</td>\n",
       "      <td>0.096875</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006618</td>\n",
       "      <td>0.018053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>406</td>\n",
       "      <td>407</td>\n",
       "      <td>563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>0.282907</td>\n",
       "      <td>0.180252</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020525</td>\n",
       "      <td>0.056074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>407 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  p_idx  p_id  mrs  unfavorable  fold0  fold1  fold2  fold3  fold4  \\\n",
       "0        0      1     1  1.0            0    val  train  train  train  train   \n",
       "1        1      2     2  1.0            0    val  train  train  train  train   \n",
       "2        2      3     3  0.0            0  train  train  train  train    val   \n",
       "3        3      4     5  0.0            0  train   test  train  train  train   \n",
       "4        4      5     6  3.0            1  train    val  train  train  train   \n",
       "..     ...    ...   ...  ...          ...    ...    ...    ...    ...    ...   \n",
       "402    402    403   555  0.0            0  train   test  train  train  train   \n",
       "403    403    404   556  0.0            0  train  train   test  train  train   \n",
       "404    404    405   557  1.0            0  train  train  train  train    val   \n",
       "405    405    406   559  1.0            0  train  train  train    val  train   \n",
       "406    406    407   563  0.0            0   test  train  train  train  train   \n",
       "\n",
       "     ... threshold_avg threshold_avg_w y_pred_class_avg y_pred_class_avg_w  \\\n",
       "0    ...      0.321884        0.303965                0                  0   \n",
       "1    ...      0.321884        0.303965                0                  0   \n",
       "2    ...      0.237775        0.329759                1                  1   \n",
       "3    ...      0.148641        0.134165                1                  1   \n",
       "4    ...      0.424493        0.432574                0                  0   \n",
       "..   ...           ...             ...              ...                ...   \n",
       "402  ...      0.148641        0.134165                1                  1   \n",
       "403  ...      0.230867        0.262792                0                  0   \n",
       "404  ...      0.237775        0.329759                0                  0   \n",
       "405  ...      0.087975        0.096875                1                  1   \n",
       "406  ...      0.282907        0.180252                0                  0   \n",
       "\n",
       "    y_pred_std  y_pred_unc  y_pred_std_w  y_pred_unc_w  pred_correct  \\\n",
       "0     0.000293    0.000760      0.000231      0.000720          True   \n",
       "1     0.010384    0.028348      0.008630      0.026852          True   \n",
       "2     0.060829    0.166263      0.032033      0.099670         False   \n",
       "3     0.082791    0.226305      0.028082      0.087377         False   \n",
       "4     0.009505    0.025944      0.008325      0.025903         False   \n",
       "..         ...         ...           ...           ...           ...   \n",
       "402   0.035988    0.098349      0.024903      0.077484         False   \n",
       "403   0.000215    0.000547      0.000049      0.000153          True   \n",
       "404   0.001949    0.005287      0.000535      0.001664          True   \n",
       "405   0.006618    0.018053      0.000000      0.000000         False   \n",
       "406   0.020525    0.056074      0.000000      0.000000          True   \n",
       "\n",
       "     pred_correct_w  \n",
       "0              True  \n",
       "1              True  \n",
       "2             False  \n",
       "3             False  \n",
       "4             False  \n",
       "..              ...  \n",
       "402           False  \n",
       "403            True  \n",
       "404            True  \n",
       "405           False  \n",
       "406            True  \n",
       "\n",
       "[407 rows x 38 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over all patients and generate heatmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of occlusions per model:  1296\n",
      "number of occlusions per axis:  [12. 12.  9.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/407 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mod_ontram\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 128, 28 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "CIB_Conv3D0 (Conv3D)            (None, 128, 128, 28, 896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D)    (None, 64, 64, 14, 3 0           CIB_Conv3D0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "CIB_Conv3D1 (Conv3D)            (None, 64, 64, 14, 3 27680       max_pooling3d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3D)  (None, 32, 32, 7, 32 0           CIB_Conv3D1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "CIB_Conv3D2 (Conv3D)            (None, 32, 32, 7, 64 55360       max_pooling3d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3D)  (None, 16, 16, 3, 64 0           CIB_Conv3D2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "CIB_Conv3D3 (Conv3D)            (None, 16, 16, 3, 64 110656      max_pooling3d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3D)  (None, 8, 8, 1, 64)  0           CIB_Conv3D3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling3d (Globa (None, 64)           0           max_pooling3d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "CIB_Dense1 (Dense)              (None, 128)          8320        global_average_pooling3d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           CIB_Dense1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "CIB_Dense2 (Dense)              (None, 128)          16512       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           CIB_Dense2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_input (InputLayer)        [(None, 15)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "CIB_dense_complex_intercept (De (None, 1)            128         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            15          dense_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2)            0           CIB_dense_complex_intercept[0][0]\n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "CIB_mod_complex_intercept (Mode (None, 1)            219552                                       \n",
      "__________________________________________________________________________________________________\n",
      "mod_linear_shift (Sequential)   (None, 1)            15                                           \n",
      "==================================================================================================\n",
      "Total params: 219,567\n",
      "Trainable params: 219,567\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "(1296, 128, 128, 28, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/407 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 1296, 527472\nPlease provide data which shares the same first dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b27ff8156eae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mboth_directions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboth_directions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0minvert_hm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minvert_hm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 normalize=norm_hm)\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mheatmaps_lc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~tf/notebooks/schnemau/xAI_stroke_3d/functions_occlusion.py\u001b[0m in \u001b[0;36mvolume_occlusion\u001b[0;34m(volume, res_tab, occlusion_size, cnn, model_names, tabular_df, normalize, both_directions, invert_hm, model_mode, occlusion_stride, input_shape, reset_cut_off)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mocc_dataset_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_tab_occ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mocc_dataset_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1247\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1249\u001b[0;31m           model=self)\n\u001b[0m\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m             label, \", \".join(str(i.shape[0]) for i in nest.flatten(data)))\n\u001b[1;32m    281\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Please provide data which shares the same first dimension.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 1296, 527472\nPlease provide data which shares the same first dimension."
     ]
    }
   ],
   "source": [
    "# lc = last conv layer\n",
    "# ac = average over all conv layer\n",
    "\n",
    "if pred_hm_only:\n",
    "    pos_hm = \"last\" # gc\n",
    "    both_directions = False # oc\n",
    "    cmap = \"jet\" # both\n",
    "    hm_positive=True # both\n",
    "else:\n",
    "    pos_hm = \"none\" # gc\n",
    "    both_directions = True # oc\n",
    "    cmap = \"bwr\" # both\n",
    "    hm_positive=False # both\n",
    "    \n",
    "if \"sigmoid\" in version or \"andrea_split\" in version or \"CI\" in version:\n",
    "    pred_idx = 0\n",
    "elif \"softmax\" in version:\n",
    "    pred_idx = 1\n",
    "    \n",
    "if hm_type == \"oc\":\n",
    "#     occ_size = (20, 20, 16)\n",
    "#     occ_stride = [6]\n",
    "    occ_size = (18, 18, 4)\n",
    "    occ_stride = (10, 10, 3)\n",
    "    num_occlusion =  int(np.prod(((np.array(res_images.shape[1:4]) - occ_size) / occ_stride) + 1))\n",
    "    print('number of occlusions per model: ', num_occlusion)\n",
    "    print(\"number of occlusions per axis: \", ((np.array(res_images.shape[1:4]) - occ_size) / occ_stride) + 1)\n",
    "\n",
    "if ens_mode == \"avg\":\n",
    "    y_pred_cl = \"y_pred_class_avg\"\n",
    "    model_mode = \"mean\"\n",
    "elif ens_mode == \"wgt\":\n",
    "    y_pred_cl = \"y_pred_class_avg_w\"\n",
    "    model_mode = \"weighted\"\n",
    "\n",
    "if generate_heatmap_and_save:\n",
    "\n",
    "    heatmaps_lc = []\n",
    "    max_hm_slices_lc = []\n",
    "    hm_mean_stds_lc = []\n",
    "    all_heatmaps_lc = []\n",
    "\n",
    "    heatmaps_ac = []\n",
    "    max_hm_slices_ac = []\n",
    "    hm_mean_stds_ac = []\n",
    "    all_heatmaps_ac = []\n",
    "\n",
    "    resized_imgs = []\n",
    "\n",
    "    for i in tqdm(range(len(res_table))):  \n",
    "        # define if and how heatmap should be inverted\n",
    "        if pred_hm_only and hm_type == \"gc\":\n",
    "            invert_hm = \"all\" if res_table[y_pred_cl][i] == 0 else \"none\"\n",
    "        elif not pred_hm_only and hm_type == \"gc\":\n",
    "            invert_hm = \"none\"\n",
    "        elif pred_hm_only and hm_type == \"oc\":\n",
    "            invert_hm = \"pred_class\"\n",
    "        elif not pred_hm_only and hm_type == \"oc\":\n",
    "            invert_hm = \"never\"\n",
    "\n",
    "        if hm_type == \"gc\":\n",
    "            heatmap, resized_img, max_hm_slice, hm_mean_std, all_heatmaps = gc.multi_models_grad_cam_3d(\n",
    "                img = res_images[i:i+1], \n",
    "                model_names = res_model_names[i],\n",
    "                cnn = model_3d,\n",
    "                layers = md.get_last_conv_layer(model_3d),\n",
    "                model_mode = model_mode,\n",
    "                pred_index = pred_idx,\n",
    "                invert_hm = invert_hm,\n",
    "                # model weigths are only used when model_mode = \"weighted\"\n",
    "                model_weights = res_table[i:i+1].reset_index(drop = True).loc[:, \n",
    "                                    res_table.columns.str.startswith(\"weight\")].to_numpy().squeeze(),\n",
    "                tabular_df = res_norm_tab,\n",
    "                pos_hm = pos_hm,\n",
    "                normalize=norm_hm)\n",
    "        elif hm_type == \"oc\":\n",
    "            heatmap, resized_img, max_hm_slice, hm_mean_std, all_heatmaps =  oc.volume_occlusion(\n",
    "                volume = res_images[i:i+1], \n",
    "                model_names = res_model_names[i],\n",
    "                res_tab = res_table[i:i+1].reset_index(drop = True),\n",
    "                tabular_df = res_norm_tab,\n",
    "                cnn = model_3d,\n",
    "                occlusion_size = np.array(occ_size), \n",
    "                occlusion_stride = occ_stride,\n",
    "                model_mode = model_mode,\n",
    "                both_directions = both_directions,\n",
    "                invert_hm = invert_hm,\n",
    "                normalize=norm_hm)\n",
    "            \n",
    "        heatmaps_lc.append(heatmap)\n",
    "        max_hm_slices_lc.append(max_hm_slice)\n",
    "        hm_mean_stds_lc.append(hm_mean_std)\n",
    "        all_heatmaps_lc.append(all_heatmaps)\n",
    "\n",
    "        if not last_layer_only and hm_type == \"gc\":\n",
    "            vis_layers = [i.name for i in model_3d.layers[1:-6]]\n",
    "            vis_layers = [vis_layer for vis_layer in vis_layers if vis_layer.startswith(\"CIB_Conv\")]    \n",
    "\n",
    "            heatmap, resized_img, max_hm_slice, hm_mean_std, all_heatmaps = gc.multi_models_grad_cam_3d(\n",
    "            img = res_images[i:i+1], \n",
    "            cnn = model_3d,\n",
    "            model_names = res_model_names[i],\n",
    "            layers = vis_layers,\n",
    "            model_mode = model_mode,\n",
    "            pred_index = pred_idx,\n",
    "            invert_hm = invert_hm,\n",
    "            tabular_df = res_norm_tab,\n",
    "            pos_hm = pos_hm)\n",
    "\n",
    "            heatmaps_ac.append(heatmap)\n",
    "            max_hm_slices_ac.append(max_hm_slice)\n",
    "            hm_mean_stds_ac.append(hm_mean_std)\n",
    "            all_heatmaps_ac.append(all_heatmaps)\n",
    "\n",
    "        resized_imgs.append(resized_img)\n",
    "        \n",
    "        gci.collect()        \n",
    "        \n",
    "else:\n",
    "    res_table = pd.read_csv(DATA_OUTPUT_DIR + \"all_tab_results_hm_unc_\" + pic_save_name + \".csv\",  sep = \",\")\n",
    "    heatmaps_lc = np.load(DATA_OUTPUT_DIR + \"all_heatmaps_\" + pic_save_name + \".npy\")\n",
    "    max_hm_slices_lc = np.load(DATA_OUTPUT_DIR + \"all_max_activation_indices_\" + pic_save_name + \".npy\", allow_pickle = True)\n",
    "    if not last_layer_only and hm_type == \"gc\":\n",
    "        heatmaps_ac = np.load(DATA_OUTPUT_DIR + \"all_heatmaps_average_conv_layer_\" + pic_save_name + \".npy\")\n",
    "        max_hm_slices_ac = np.load(DATA_OUTPUT_DIR + \"all_max_activation_indices_laverage_conv_layer_\" + pic_save_name + \".npy\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hm_type == \"gc\" and not norm_hm:\n",
    "    hm_min = np.min(heatmaps_lc)\n",
    "    hm_max = np.max(heatmaps_lc)\n",
    "    print(hm_min, hm_max)\n",
    "    np.save(DATA_OUTPUT_DIR + \"hm_min_max_\" + pic_save_name, np.array([hm_min, hm_max]))\n",
    "    \n",
    "    heatmaps_lc = fm.normalize_heatmap(np.array(heatmaps_lc), both_directions=False, hm_min_max = (hm_min, hm_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-f39dfbeaefa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mgenerate_heatmap_and_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mres_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"heatmap_std_last_layer\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhm_mean_stds_lc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     res_table[\"heatmap_unc_last_layer\"] = (res_table[\"heatmap_std_last_layer\"] - res_table.heatmap_std_last_layer.min()) / (\n\u001b[1;32m      4\u001b[0m         res_table.heatmap_std_last_layer.max() - res_table.heatmap_std_last_layer.min())\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2937\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2938\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2999\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3000\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3001\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3635\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3636\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3637\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3638\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[0;34m(data, index, copy)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Length of values does not match length of index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "if generate_heatmap_and_save:   \n",
    "    res_table[\"heatmap_std_last_layer\"] = hm_mean_stds_lc\n",
    "    res_table[\"heatmap_unc_last_layer\"] = (res_table[\"heatmap_std_last_layer\"] - res_table.heatmap_std_last_layer.min()) / (\n",
    "        res_table.heatmap_std_last_layer.max() - res_table.heatmap_std_last_layer.min())\n",
    "    \n",
    "    if not last_layer_only:\n",
    "        res_table[\"heatmap_std_avg_layer\"] = hm_mean_stds_ac\n",
    "        res_table[\"heatmap_unc_avg_layer\"] = (res_table[\"heatmap_std_avg_layer\"] - res_table.heatmap_std_avg_layer.min()) / (\n",
    "            res_table.heatmap_std_avg_layer.max() - res_table.heatmap_std_avg_layer.min())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Metrics\n",
    "\n",
    "Calculate heatmap uncertainty. Which is the normalized (min-max) averaged standard deviation over each pixel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not last_layer_only and hm_type == \"gc\":\n",
    "    print(np.corrcoef(res_table[\"heatmap_unc_avg_layer\"], res_table[\"heatmap_unc_last_layer\"]))\n",
    "    print(np.corrcoef(res_table[\"y_pred_unc\"], res_table[\"heatmap_unc_avg_layer\"]))\n",
    "print(np.corrcoef(res_table[\"y_pred_unc\"], res_table[\"heatmap_unc_last_layer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not last_layer_only and hm_type == \"gc\":\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize = (15, 5))\n",
    "else:\n",
    "    fig, (ax1, ax3) = plt.subplots(1,2, figsize = (10, 5))\n",
    "\n",
    "sns.boxplot(x = \"unfavorable\",\n",
    "    y = \"y_pred_unc\",\n",
    "    data = res_table,\n",
    "    ax = ax1)\n",
    "sns.stripplot(x = \"unfavorable\",\n",
    "    y = \"y_pred_unc\",\n",
    "    hue = y_pred_cl,\n",
    "    alpha = 0.75,\n",
    "    palette=[\"C2\", \"C3\"],\n",
    "    data = res_table,\n",
    "    ax = ax1)\n",
    "ax1.legend(title='predicted class', loc='upper center')\n",
    "ax1.set(xlabel='true class', ylabel='prediction uncertainty')\n",
    "\n",
    "if not last_layer_only:\n",
    "    sns.boxplot(x = \"unfavorable\",\n",
    "        y = \"heatmap_unc_avg_layer\",\n",
    "        data = res_table,\n",
    "        ax = ax2)\n",
    "    sns.stripplot(x = \"unfavorable\",\n",
    "        y = \"heatmap_unc_avg_layer\",\n",
    "        hue = y_pred_cl,\n",
    "        alpha = 0.75,\n",
    "        palette=[\"C2\", \"C3\"],\n",
    "        data = res_table,\n",
    "        ax = ax2)\n",
    "    ax2.legend(title='predicted class', loc='upper center')\n",
    "    ax2.set(xlabel='true class', ylabel='heatmap uncertainty avg layer')\n",
    "\n",
    "sns.boxplot(x = \"unfavorable\",\n",
    "    y = \"heatmap_unc_last_layer\",\n",
    "    data = res_table,\n",
    "    ax = ax3)\n",
    "sns.stripplot(x = \"unfavorable\",\n",
    "    y = \"heatmap_unc_last_layer\",\n",
    "    hue = y_pred_cl,\n",
    "    alpha = 0.75,\n",
    "    palette=[\"C2\", \"C3\"],\n",
    "    data = res_table,\n",
    "    ax = ax3)\n",
    "ax3.legend(title='predicted class', loc='upper center')\n",
    "ax3.set(xlabel='true class', ylabel='heatmap uncertainty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(\n",
    "           x = \"heatmap_unc_last_layer\",\n",
    "           y = \"y_pred_unc\",\n",
    "            data = res_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Heatmaps, Images and updated Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if generate_heatmap_and_save:\n",
    "    res_table.to_csv(DATA_OUTPUT_DIR + \"all_tab_results_hm_unc_\" + pic_save_name + \".csv\",  index=False)\n",
    "    np.save(DATA_OUTPUT_DIR + \"all_heatmaps_\" + pic_save_name + \".npy\", heatmaps_lc)\n",
    "    np.save(DATA_OUTPUT_DIR + \"all_max_activation_indices_\" + pic_save_name + \".npy\", max_hm_slices_lc)\n",
    "    np.save(DATA_OUTPUT_DIR + \"all_ensemble_heatmaps_\" + pic_save_name + \".npy\", all_heatmaps_lc)\n",
    "    \n",
    "    if not last_layer_only and hm_type == \"gc\":\n",
    "        np.save(DATA_OUTPUT_DIR + \"all_heatmaps_average_conv_layer_\" + pic_save_name + \".npy\", heatmaps_ac)\n",
    "        np.save(DATA_OUTPUT_DIR + \"all_max_activation_indices_laverage_conv_layer_\" + pic_save_name + \".npy\", max_hm_slices_ac)\n",
    "        np.save(DATA_OUTPUT_DIR + \"all_ensemble_heatmaps_average_conv_layer_\" + pic_save_name + \".npy\", all_heatmaps_ac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Average Heatmaps\n",
    "\n",
    "Plot the average heatmaps for all patients. Once for class 0, once for class 1 and once for all patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.where(res_table[y_pred_cl] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_hm_lc = np.array(np.take(heatmaps_lc, idx, axis = 0).squeeze()).mean(axis = 0)\n",
    "if not last_layer_only:\n",
    "    mean_hm_ac = np.array(np.take(heatmaps_ac, idx, axis = 0).squeeze()).mean(axis = 0)\n",
    "mean_image = np.array(np.take(res_images, idx, axis = 0).squeeze()).mean(axis = 0)\n",
    "\n",
    "phm.plot_heatmap(mean_image, mean_hm_lc,\n",
    "            version = \"overlay\",\n",
    "            mode = \"avg\",\n",
    "            hm_colormap = cmap,\n",
    "            hm_positive = hm_positive)\n",
    "if not last_layer_only:\n",
    "    phm.plot_heatmap(mean_image, mean_hm_ac,\n",
    "                version = \"overlay\",\n",
    "                mode = \"avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.where(res_table[y_pred_cl] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_hm_lc = np.array(np.take(heatmaps_lc, idx, axis = 0).squeeze()).mean(axis = 0)\n",
    "if not last_layer_only:\n",
    "    mean_hm_ac = np.array(np.take(heatmaps_ac, idx, axis = 0).squeeze()).mean(axis = 0)\n",
    "mean_image = np.array(np.take(res_images, idx, axis = 0).squeeze()).mean(axis = 0)\n",
    "\n",
    "phm.plot_heatmap(mean_image, mean_hm_lc,\n",
    "            version = \"overlay\",\n",
    "            mode = \"avg\",\n",
    "            hm_colormap = cmap,\n",
    "            hm_positive = hm_positive)\n",
    "if not last_layer_only:\n",
    "    phm.plot_heatmap(mean_image, mean_hm_ac,\n",
    "                version = \"overlay\",\n",
    "                mode = \"avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(0,407)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_hm_lc = np.array(np.take(heatmaps_lc, idx, axis = 0).squeeze()).mean(axis = 0)\n",
    "if not last_layer_only:\n",
    "    mean_hm_ac = np.array(np.take(heatmaps_ac, idx, axis = 0).squeeze()).mean(axis = 0)\n",
    "mean_image = np.array(np.take(res_images, idx, axis = 0).squeeze()).mean(axis = 0)\n",
    "\n",
    "phm.plot_heatmap(mean_image, mean_hm_lc,\n",
    "            version = \"overlay\",\n",
    "            mode = \"avg\",\n",
    "            hm_colormap = cmap,\n",
    "            hm_positive = hm_positive)\n",
    "if not last_layer_only:\n",
    "    phm.plot_heatmap(mean_image, mean_hm_ac,\n",
    "                version = \"overlay\",\n",
    "                mode = \"avg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Plots as PNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if generate_pictures:\n",
    "    if not last_layer_only:\n",
    "        phm.plot_gradcams_last_avg_org(\n",
    "            res_table = res_table, \n",
    "            vis_layers = vis_layers,\n",
    "            res_images = res_images,\n",
    "            res_model_names = res_model_names,\n",
    "            model_3d = model_3d,\n",
    "            layer_mode = \"mean\", \n",
    "            heatmap_mode = \"avg\", \n",
    "            save_path = PIC_OUTPUT_DIR, \n",
    "            save_name = pic_save_name, save = True)\n",
    "\n",
    "        phm.plot_gradcams_last_avg_org(\n",
    "            res_table = res_table, \n",
    "            vis_layers = vis_layers,\n",
    "            res_images = res_images,\n",
    "            res_model_names = res_model_names,\n",
    "            model_3d = model_3d,\n",
    "            layer_mode = \"mean\",\n",
    "            heatmap_mode = \"max\", \n",
    "            save_path = PIC_OUTPUT_DIR, \n",
    "            save_name = pic_save_name, save = True)\n",
    "    else:\n",
    "        phm.plot_heatmaps_avg_max_org(\n",
    "            pat_data = pat_orig_tab,\n",
    "            res_table = res_table, \n",
    "            res_images = res_images,\n",
    "            heatmaps = heatmaps_lc,\n",
    "            cmap = cmap,\n",
    "            hm_positive = hm_positive,\n",
    "            save_path = PIC_OUTPUT_DIR, \n",
    "            save_name = pic_save_name, save = True,\n",
    "            res_mode=ens_mode)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Plots to PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only_wrong_out = True # should already be defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not only_wrong_out: # all ids\n",
    "    pat_ids = list(res_table[\"p_id\"])\n",
    "else: # only ids with low uncertainty and wrong classified\n",
    "    # pat_ids = list(res_table.query(\"pred_correct == False and y_pred_unc < 0.2\").p_id)\n",
    "    pat_ids = list(res_table.query(\"pred_correct == False\").p_id)\n",
    "    res_table[res_table.p_id.isin(pat_ids)].to_csv(\n",
    "        DATA_OUTPUT_DIR + \"all_tab_results_hm_unc_\" + pic_save_name + \"_wrong_cl.csv\",  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_table[res_table.p_id.isin(pat_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = FPDF()\n",
    "pdf.set_auto_page_break(0)\n",
    "\n",
    "# imagelist is the list with all image filenames\n",
    "for patient in tqdm(pat_ids):\n",
    "    \n",
    "    name_start = PIC_OUTPUT_DIR + \"pat\" + str(patient) + \"_\" + pic_save_name\n",
    "    \n",
    "    if not last_layer_only:\n",
    "        pdf.add_page(orientation=\"L\")  # Use default page size (A4) in landscape mode\n",
    "        pdf.set_left_margin(10)\n",
    "        pdf.set_right_margin(10)\n",
    "        x, y, w, h = (0, 10, 190, 190)\n",
    "        pdf.image(name_start + \"_last_and_all_layers_avg.png\", x, y, w, h)\n",
    "        x, y, w, h = (140, 10, 190, 190)\n",
    "        pdf.image(name_start + \"_last_and_all_layers_max.png\", x, y, w, h)\n",
    "    else:\n",
    "        pdf.add_page(orientation=\"P\")  # Use default page size (A4) in portrait mode\n",
    "        pdf.set_left_margin(10)\n",
    "        pdf.set_right_margin(10)\n",
    "        x, y, w, h = (0, 10, 205, 205)\n",
    "        pdf.image(name_start + \"_last_layer_avg_max_orig.png\", x, y, w, h)\n",
    "\n",
    "if only_wrong_out:\n",
    "    pdf.output(PIC_OUTPUT_DIR + \"0_all_heatmaps_\" + pic_save_name + \"_all_patients_wrong_cl.pdf\", \"F\")\n",
    "else:\n",
    "    pdf.output(PIC_OUTPUT_DIR + \"0_all_heatmaps_\" + pic_save_name + \"_all_patients.pdf\", \"F\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
