{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF  Version 2.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils import to_categorical\n",
    "print(\"TF  Version\",tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check and set path before loading modules\n",
    "INPUT_DIR = \"/tf/notebooks/schnemau/xAI_stroke_3d/\"\n",
    "OUTPUT_DIR = \"/tf/notebooks/bule/explainable_AI/\"\n",
    "if os.getcwd() != OUTPUT_DIR:\n",
    "    os.chdir(OUTPUT_DIR)\n",
    "    \n",
    "import functions_model_definition as md\n",
    "import functions_read_data as rdat\n",
    "import functions_slider as sl\n",
    "#weights tuning functions\n",
    "import ens_weights_tuning as w_tune\n",
    "\n",
    "#ontram functions\n",
    "from k_ontram_functions.ontram import ontram\n",
    "from k_ontram_functions.ontram_loss import ontram_loss\n",
    "from k_ontram_functions.ontram_metrics import ontram_acc, ontram_auc\n",
    "from k_ontram_functions.ontram_predict import predict_ontram, get_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Version\n",
    "# version = \"CIBLSX\" # one of:\n",
    "version = \"CIBLSX\" # one of:\n",
    "\n",
    "# Define Model Version\n",
    "model_version = 4\n",
    "\n",
    "# Select naming convention (for CIBLSX model_version >= 3 should be False)\n",
    "comp_mode = False # if True: use old naming convention\n",
    "\n",
    "# define paths\n",
    "DATA_DIR, WEIGHT_DIR, DATA_OUTPUT_DIR, PIC_OUTPUT_DIR, pic_save_name = rdat.dir_setup(\n",
    "    INPUT_DIR, OUTPUT_DIR, version, model_version, \n",
    "    compatibility_mode=comp_mode)\n",
    "\n",
    "save_csv = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Table does not exist for CIBLSX M4. Returning None for all_results_tab.\n"
     ]
    }
   ],
   "source": [
    "## load images and ids\n",
    "(X_in, pat_ids, id_tab, all_results_tab, pat_orig_tab, pat_norm_tab, num_models) = rdat.version_setup(\n",
    "    DATA_DIR = DATA_DIR, \n",
    "    version = version, \n",
    "    model_version = model_version,\n",
    "    compatibility_mode=comp_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "(input_dim_img, output_dim, LOSS, layer_connection, last_activation) = md.model_setup(version)\n",
    "\n",
    "model_3d = md.model_init(\n",
    "    version = version, \n",
    "    output_dim = output_dim,\n",
    "    LOSS = LOSS,\n",
    "    layer_connection = layer_connection,\n",
    "    last_activation = last_activation,\n",
    "    C = 2,\n",
    "    learning_rate = 5*1e-5,\n",
    "    batch_size = 6,\n",
    "    input_dim = input_dim_img,\n",
    "    input_dim_tab = pat_norm_tab.drop(columns=[\"p_id\"]).shape[1] if \"LSX\" in version else None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model Name\n",
    "generate_model_name = md.set_generate_model_name(\n",
    "    model_version = model_version, \n",
    "    layer_connection = layer_connection, \n",
    "    last_activation = last_activation, \n",
    "    path = WEIGHT_DIR,\n",
    "    compatability_mode=comp_mode)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nrs = list(range(5)) #num of ensembles\n",
    "which_splits = list(range(0,10)) # 10 Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shapes (13, 1) and (27, 1) are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-919e453dd188>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmodel_nr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_nrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mmodel_3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_model_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhich_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_nr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m#test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[1;32m    248\u001b[0m         raise ValueError('Load weights is not yet supported with TPUStrategy '\n\u001b[1;32m    249\u001b[0m                          'with steps_per_run greater than 1.')\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_mismatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m   def compile(self,\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[1;32m   1264\u001b[0m             f, self.layers, skip_mismatch=skip_mismatch)\n\u001b[1;32m   1265\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m         \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m    705\u001b[0m                        str(len(weight_values)) + ' elements.')\n\u001b[1;32m    706\u001b[0m     \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m   \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   3382\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly_outside_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3383\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3384\u001b[0;31m       \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3385\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3386\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    844\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_handle_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m       \u001b[0mvalue_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m       assign_op = gen_resource_variable_ops.assign_variable_op(\n\u001b[1;32m    848\u001b[0m           self.handle, value_tensor, name=name)\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1115\u001b[0m     \"\"\"\n\u001b[1;32m   1116\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shapes %s and %s are incompatible\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mmost_specific_compatible_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes (13, 1) and (27, 1) are incompatible"
     ]
    }
   ],
   "source": [
    "results_list = [] \n",
    "valid_list = [] \n",
    "weights = []\n",
    "betas = []\n",
    "\n",
    "for which_split in which_splits:\n",
    "    data_split = rdat.split_data(id_tab, X_in, which_split, X_tab = pat_norm_tab)\n",
    "\n",
    "    X_valid = np.expand_dims(data_split[\"X\"][\"valid\"], axis=-1)\n",
    "    X_test = np.expand_dims(data_split[\"X\"][\"test\"], axis=-1)\n",
    "    Y_valid = to_categorical(data_split[\"y\"][\"valid\"])\n",
    "    Y_test = to_categorical(data_split[\"y\"][\"test\"])\n",
    "\n",
    "    if pat_norm_tab is not None:\n",
    "        X_tab_test = data_split[\"X_tab\"][\"test\"]    \n",
    "        X_tab_valid = data_split[\"X_tab\"][\"valid\"]\n",
    "        test_data = tf.data.Dataset.from_tensor_slices((X_test, X_tab_test))\n",
    "        valid_data = tf.data.Dataset.from_tensor_slices((X_valid, X_tab_valid))\n",
    "        shift_params = []\n",
    "    else:\n",
    "        X_tab_test = None\n",
    "        X_tab_valid = None\n",
    "        test_data = tf.data.Dataset.from_tensor_slices((X_test))\n",
    "        valid_data = tf.data.Dataset.from_tensor_slices((X_valid))\n",
    "        shift_params = None\n",
    "\n",
    "    test_labels = tf.data.Dataset.from_tensor_slices((Y_test))\n",
    "    test_loader = tf.data.Dataset.zip((test_data, test_labels))\n",
    "    test_dataset_pred = (test_loader.batch(len(X_test)))\n",
    "\n",
    "    valid_labels = tf.data.Dataset.from_tensor_slices((Y_valid))\n",
    "    valid_loader = tf.data.Dataset.zip((valid_data, valid_labels))\n",
    "    valid_dataset_pred = (valid_loader.batch(len(X_valid)))  \n",
    "\n",
    "    results = id_tab[id_tab[\"fold\" + str(which_split)] == \"test\"].copy()       \n",
    "    results[\"test_split\"] = which_split        \n",
    "        \n",
    "    validation_results = pd.DataFrame(\n",
    "            {\"test_split\": which_split,\n",
    "            \"unfavorable\": data_split[\"y\"][\"valid\"]})\n",
    "      \n",
    "    y_test_preds = []\n",
    "    y_valid_preds = []   \n",
    "    intercepts_test = []\n",
    "    intercepts_val = []\n",
    "    \n",
    "    for model_nr in model_nrs:\n",
    "        model_3d.load_weights(generate_model_name(which_split, model_nr))\n",
    "\n",
    "        #test\n",
    "        predic = predict_ontram(model_3d, data = test_dataset_pred)['pdf'][:,1]\n",
    "        y_test_preds.append(predic.squeeze())\n",
    "        results[\"y_pred_model_\" + str(model_nr)] = y_test_preds[-1]\n",
    "\n",
    "        #valid\n",
    "        predicc = predict_ontram(model_3d, data = valid_dataset_pred)['pdf'][:,1]\n",
    "        y_valid_preds.append(predicc.squeeze())\n",
    "        validation_results[\"y_pred_model_\" + str(model_nr)] = y_valid_preds[-1]   \n",
    "\n",
    "        # Save Intercepts for tuning\n",
    "        #test\n",
    "        preds_test = model_3d.predict(test_dataset_pred)\n",
    "        intercepts_test.append(preds_test[:, 0])\n",
    "        #valid\n",
    "        preds_val = model_3d.predict(valid_dataset_pred)\n",
    "        intercepts_val.append(preds_val[:, 0])\n",
    "\n",
    "        # Save shift parameters if CIB_LSX\n",
    "        if shift_params is not None:\n",
    "            shift_params.append(get_parameters(model_3d)['shift'][0][0][0])       \n",
    "\n",
    "    y_test_preds = np.array(y_test_preds)\n",
    "    y_valid_preds = np.array(y_valid_preds) \n",
    "\n",
    "    weigths_tuned = w_tune.get_w(intercepts = intercepts_val,\n",
    "                             y_true = data_split[\"y\"][\"valid\"],\n",
    "                             shift = shift_params,\n",
    "                             X_tab = X_tab_valid)\n",
    "    \n",
    "    for model_nr in model_nrs:\n",
    "        results[f'weight_model_{model_nr}'] = weigths_tuned[model_nr]\n",
    "        validation_results[f'weight_model_{model_nr}'] = weigths_tuned[model_nr]\n",
    "\n",
    "    results[\"y_pred_trafo_avg\"] = w_tune.get_ensemble(intercepts = intercepts_test, \n",
    "                                                      shift = shift_params, \n",
    "                                                      X_tab = X_tab_test, \n",
    "                                                      weights=None)\n",
    "    \n",
    "    results[\"y_pred_trafo_avg_w\"] = w_tune.get_ensemble(intercepts = intercepts_test, \n",
    "                                                      shift = shift_params, \n",
    "                                                      X_tab = X_tab_test, \n",
    "                                                      weights=weigths_tuned)\n",
    "    \n",
    "    validation_results[\"y_pred_trafo_avg\"] = w_tune.get_ensemble(intercepts = intercepts_val, \n",
    "                                                      shift = shift_params, \n",
    "                                                      X_tab = X_tab_valid, \n",
    "                                                      weights=None) \n",
    "    \n",
    "    validation_results[\"y_pred_trafo_avg_w\"] = w_tune.get_ensemble(intercepts = intercepts_val, \n",
    "                                                      shift = shift_params, \n",
    "                                                      X_tab = X_tab_valid, \n",
    "                                                      weights=weigths_tuned)\n",
    "    \n",
    "    results_list.append(results)\n",
    "    valid_list.append(validation_results)\n",
    "    betas.append(shift_params)\n",
    "    weights.append(weigths_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Threshold\n",
    "\n",
    "Calculation of threshold for classification is done on validation data. Then applied to the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_thresholds_avg = []\n",
    "valid_thresholds_avg_w = []\n",
    "\n",
    "for i, validation_results in enumerate(valid_list):\n",
    "  \n",
    "    y_org = validation_results[\"unfavorable\"]\n",
    "    y_pred_avg = validation_results[\"y_pred_trafo_avg\"]\n",
    "    y_pred_avg_w = validation_results[\"y_pred_trafo_avg_w\"]\n",
    "  \n",
    "    # calculate fpr, tpr and thresholds\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_org, y_pred_avg)\n",
    "    fpr_w, tpr_w, threshold_w = metrics.roc_curve(y_org, y_pred_avg_w)\n",
    "\n",
    "    #auc\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    roc_auc_w = metrics.auc(fpr_w, tpr_w)\n",
    "    \n",
    "    # calculate geometric mean of tpr and fpr to find best threshold\n",
    "    gmean = np.sqrt(tpr * (1 - fpr))\n",
    "    gmean_w = np.sqrt(tpr_w * (1 - fpr_w))\n",
    "\n",
    "    # Find the optimal threshold\n",
    "    index = np.argmax(gmean)\n",
    "    index_w = np.argmax(gmean_w)\n",
    "\n",
    "    valid_thresholds_avg.append(threshold[index])\n",
    "    valid_thresholds_avg_w.append(threshold_w[index_w])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Threshold to Testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, results in enumerate(results_list):\n",
    "    results[\"threshold_avg\"] = valid_thresholds_avg[i]\n",
    "    results[\"threshold_avg_w\"] = valid_thresholds_avg_w[i]\n",
    "    \n",
    "    results[\"y_pred_class_avg\"] = (results[\"y_pred_trafo_avg\"] >= results[\"threshold_avg\"]).astype(int)\n",
    "    results[\"y_pred_class_avg_w\"] = (results[\"y_pred_trafo_avg_w\"] >= results[\"threshold_avg_w\"]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concat all Pandas and Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = pd.concat(results_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Model Uncertainty\n",
    "\n",
    "Use the standard deviation of the predictions as a measure of uncertainty. Then use min max normalization to scale the uncertainty between 0 and 1.  \n",
    "Compare the uncertainty with the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results[\"y_pred_std\"] = all_results[[\"y_pred_model_\" + str(i) for i in range(5)]].std(axis = 1)\n",
    "all_results[\"y_pred_unc\"] = (all_results[\"y_pred_std\"] - all_results.y_pred_std.min()) / (\n",
    "    all_results.y_pred_std.max() - all_results.y_pred_std.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_means = np.average(all_results[[\"y_pred_model_\" + str(i) for i in range(5)]],\n",
    "                            weights=all_results[[\"weight_model_\" + str(i) for i in range(5)]],\n",
    "                            axis=1)\n",
    "\n",
    "weighted_var = np.average((all_results[[\"y_pred_model_\" + str(i) for i in range(5)]] - weighted_means[:, np.newaxis])**2,\n",
    "                                         weights=all_results[[\"weight_model_\" + str(i) for i in range(5)]],\n",
    "                                         axis=1)\n",
    "\n",
    "all_results[\"y_pred_std_w\"] = np.sqrt(weighted_var)\n",
    "\n",
    "all_results[\"y_pred_unc_w\"] = (all_results[\"y_pred_std_w\"] - all_results[\"y_pred_std_w\"].min()) / (\n",
    "        all_results[\"y_pred_std_w\"].max() - all_results[\"y_pred_std_w\"].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results[\"pred_correct\"] = all_results[\"y_pred_class_avg\"] == all_results[\"unfavorable\"] \n",
    "all_results[\"pred_correct_w\"] = all_results[\"y_pred_class_avg_w\"] == all_results[\"unfavorable\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not comp_mode:\n",
    "    res_name = DATA_DIR + \"all_tab_results_\" + version + \"_M\" + str(model_version) + \".csv\" # 10 Fold\n",
    "\n",
    "elif comp_mode:\n",
    "    res_name = DATA_DIR + \"all_tab_results_10Fold_\" + version + \"_M\" + str(model_version) + \".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_csv == True:\n",
    "    all_results.to_csv(res_name,  index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Shift Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if version == \"CIBLSX\":\n",
    "    betas = np.array(betas)\n",
    "    weights = np.array(weights)\n",
    "\n",
    "    num_levels = 10 # axis 0\n",
    "    num_sublevels = 5 # axis 1\n",
    "    num_parameters = 13 # axis 2\n",
    "\n",
    "    means_per_level = np.mean(betas, axis=1)\n",
    "\n",
    "    means_per_level_w = []\n",
    "    for i in range(betas.shape[0]):\n",
    "        means_per_level_w.append(np.average(betas[i], axis=0, weights=weights[i]))\n",
    "    means_per_level_w = np.array(means_per_level_w)\n",
    "\n",
    "    means_per_parameter = means_per_level.transpose(1, 0, 2).reshape(num_parameters, num_levels)\n",
    "    means_per_parameter_w = means_per_level_w.transpose(1, 0, 2).reshape(num_parameters, num_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if version == \"CIBLSX\":\n",
    "    variable_names = [\"age\", \"sexm\", \"nihss_baseline\", \"mrs_before\",\n",
    "                    \"stroke_beforey\", \"tia_beforey\", \"ich_beforey\", \n",
    "                    \"rf_hypertoniay\", \"rf_diabetesy\", \"rf_hypercholesterolemiay\", \n",
    "                    \"rf_smokery\", \"rf_atrial_fibrillationy\", \"rf_chdy\"]\n",
    "\n",
    "    # Plotting boxplot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.boxplot(means_per_parameter.T, labels=variable_names)\n",
    "    plt.axhline(0, color='black', lw=1, linestyle='--')\n",
    "    plt.title('Boxplot of Mean Log-Odds Ratio')\n",
    "    plt.xlabel('Variable name')\n",
    "    plt.ylabel('Estimated average Betas')\n",
    "    plt.grid(False)  # Remove grid lines\n",
    "    plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if version == \"CIBLSX\":\n",
    "    variable_names = [\"age\", \"sexm\", \"nihss_baseline\", \"mrs_before\",\n",
    "                    \"stroke_beforey\", \"tia_beforey\", \"ich_beforey\", \n",
    "                    \"rf_hypertoniay\", \"rf_diabetesy\", \"rf_hypercholesterolemiay\", \n",
    "                    \"rf_smokery\", \"rf_atrial_fibrillationy\", \"rf_chdy\"]\n",
    "\n",
    "    # Plotting boxplot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.boxplot(means_per_parameter_w.T, labels=variable_names)\n",
    "    plt.axhline(0, color='black', lw=1, linestyle='--')\n",
    "    plt.title('Boxplot of Mean Log-Odds Ratio')\n",
    "    plt.xlabel('Variable name')\n",
    "    plt.ylabel('Estimated average Betas')\n",
    "    plt.grid(False)  # Remove grid lines\n",
    "    plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def plot_beta_values(coef_df): \n",
    "\n",
    "    df_reshaped = coef_df.melt(var_name='Variable', value_name='Value').reset_index().rename(columns={'index': 'model_nr'})\n",
    "    df_reshaped['model_nr'] = df_reshaped['model_nr'] % len(coef_df)\n",
    "\n",
    "    # Sort the dataframe by the highest mean of each variable\n",
    "    df_sorted = df_reshaped.groupby('Variable')['Value'].mean().sort_values(ascending=False).index\n",
    "    df_reshaped['Variable'] = pd.Categorical(df_reshaped['Variable'], categories=df_sorted, ordered=True)\n",
    "\n",
    "    # Plotting boxplot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(\n",
    "        y = \"Variable\", \n",
    "        x = \"Value\",\n",
    "        data = df_reshaped,\n",
    "        color = \"lightgrey\",\n",
    "        width = 0.5,\n",
    "        )\n",
    "    sns.stripplot(\n",
    "        y = \"Variable\", \n",
    "        x = \"Value\",\n",
    "        # hue = \"model_nr\",\n",
    "        data = df_reshaped,\n",
    "        color = \"black\",\n",
    "        jitter=False,\n",
    "        alpha = 0.75)\n",
    "    plt.axvline(0, color='black', lw=1, linestyle='--')\n",
    "    plt.title('Boxplot of weighted Log-Odds Ratio')\n",
    "    plt.xlabel('Estimated weighted Betas')\n",
    "    plt.ylabel('Variable')\n",
    "    plt.yticks(ha='right')  # Rotate y-axis labels for better readability\n",
    "    plt.tight_layout()\n",
    "    plt.grid(axis = \"x\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if version == \"CIBLSX\": \n",
    "\n",
    "    plot_beta_values(pd.DataFrame(means_per_parameter_w.T, columns=variable_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_norm_tab.mrs_before.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def fit_log_reg(x_train, y_train, oh_mrs_before = False, stand_oh_mrs_before = False):\n",
    "    # x_train: pandas dataframe with training data\n",
    "    # y_train: pandas series with target variable\n",
    "    # oh_mrs_before: boolean, whether to one-hot encode mrs_before\n",
    "    # stand_oh_mrs_before: boolean, whether to standardize one-hot encoded mrs_before (only relevant if oh_mrs_before is True)\n",
    "\n",
    "    if oh_mrs_before:\n",
    "        x_train = pd.get_dummies(x_train, columns=['mrs_before'], drop_first=True)\n",
    "\n",
    "        x_train.rename(columns={\n",
    "            'mrs_before_0.705288128801963': 'mrs_bl_1',\n",
    "            'mrs_before_1.8815416857184': 'mrs_bl_2',\n",
    "            'mrs_before_3.05779524263483': 'mrs_bl_3',\n",
    "            'mrs_before_4.2340487995512595': 'mrs_bl_4'\n",
    "        }, inplace=True)\n",
    "\n",
    "        if stand_oh_mrs_before:\n",
    "            x_train['mrs_bl_1'] = (x_train['mrs_bl_1'] - x_train['mrs_bl_1'].mean()) / x_train['mrs_bl_1'].std()\n",
    "            x_train['mrs_bl_2'] = (x_train['mrs_bl_2'] - x_train['mrs_bl_2'].mean()) / x_train['mrs_bl_2'].std()\n",
    "            x_train['mrs_bl_3'] = (x_train['mrs_bl_3'] - x_train['mrs_bl_3'].mean()) / x_train['mrs_bl_3'].std()\n",
    "            x_train['mrs_bl_4'] = (x_train['mrs_bl_4'] - x_train['mrs_bl_4'].mean()) / x_train['mrs_bl_4'].std()\n",
    "\n",
    "            print(x_train['mrs_bl_1'].mean(), x_train['mrs_bl_1'].std())\n",
    "\n",
    "\n",
    "    logreg = LogisticRegression()\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    logreg.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "    coef_names = x_train.columns\n",
    "    coef_values = logreg.coef_[0]\n",
    "\n",
    "    df = pd.DataFrame(np.expand_dims(coef_values, axis = 0), columns=coef_names)\n",
    "\n",
    "    return (df, logreg.intercept_[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = []\n",
    "coefficients_oh = []\n",
    "coefficients_oh_stand = []\n",
    "intercepts = []\n",
    "intercepts_oh = []\n",
    "intercepts_oh_stand = []\n",
    "\n",
    "for which_split in which_splits:\n",
    "    data_split = rdat.split_data(id_tab, X_in, which_split, X_tab = pat_norm_tab)\n",
    "\n",
    "    tab_train = data_split[\"X_tab\"][\"train\"]\n",
    "    tab_train = pd.DataFrame(tab_train, columns = pat_norm_tab.drop(columns=[\"p_id\"]).columns)\n",
    "    y_train = data_split[\"y\"][\"train\"]    \n",
    "\n",
    "    log_fit = fit_log_reg(tab_train, y_train, oh_mrs_before = False)\n",
    "    log_fit_oh = fit_log_reg(tab_train, y_train, oh_mrs_before = True)\n",
    "    log_fit_oh_stand = fit_log_reg(tab_train, y_train, oh_mrs_before = True, stand_oh_mrs_before = True)\n",
    "\n",
    "    coefficients.append(log_fit[0])\n",
    "    coefficients_oh.append(log_fit_oh[0])\n",
    "    coefficients_oh_stand.append(log_fit_oh_stand[0])\n",
    "    intercepts.append(log_fit[1])\n",
    "    intercepts_oh.append(log_fit_oh[1])\n",
    "    intercepts_oh_stand.append(log_fit_oh_stand[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_beta_values(pd.concat(coefficients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_beta_values(pd.concat(coefficients_oh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_beta_values(pd.concat(coefficients_oh_stand))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = all_results[\"unfavorable\"]\n",
    "y_pred_binary = all_results[\"y_pred_class_avg\"]\n",
    "y_pred_binary_w = all_results[\"y_pred_class_avg_w\"]\n",
    "\n",
    "y_pred_trafo_avg = all_results[\"y_pred_trafo_avg\"]\n",
    "y_pred_trafo_avg_w = all_results[\"y_pred_trafo_avg_w\"]\n",
    "\n",
    "# Calculate metrics average weighted\n",
    "f1_value = metrics.f1_score(y_true, y_pred_binary)\n",
    "accuracy = metrics.accuracy_score(y_true, y_pred_binary)\n",
    "sensitivity = metrics.recall_score(y_true, y_pred_binary)\n",
    "specificity = metrics.recall_score(y_true, y_pred_binary, pos_label=0)\n",
    "auc_value = metrics.roc_auc_score(y_true, y_pred_trafo_avg)\n",
    "log_li = metrics.log_loss(y_true, y_pred_trafo_avg)\n",
    "\n",
    "# Calculate metrics tuned weighted average\n",
    "f1_value_w = metrics.f1_score(y_true, y_pred_binary_w)\n",
    "accuracy_w = metrics.accuracy_score(y_true, y_pred_binary_w)\n",
    "sensitivity_w = metrics.recall_score(y_true, y_pred_binary_w)\n",
    "specificity_w = metrics.recall_score(y_true, y_pred_binary_w, pos_label=0)\n",
    "auc_value_w = metrics.roc_auc_score(y_true, y_pred_trafo_avg_w)\n",
    "log_li_w = metrics.log_loss(y_true, y_pred_trafo_avg_w)\n",
    "\n",
    "# Display results 1\n",
    "print(\"---Trafo Average:---\")\n",
    "print(\"F1-Value:\", round(f1_value,4))\n",
    "print(\"Accuracy:\", round(accuracy,4))\n",
    "print(\"Sensitivity:\", round(sensitivity,4))\n",
    "print(\"Specificity:\", round(specificity,4))\n",
    "print(\"AUC:\", round(auc_value,4))\n",
    "print(\"Negative Log-Likelihood:\", round(log_li,4))\n",
    "\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "# Display results 2\n",
    "print(\"---Trafo Average weighted tuned:---\")\n",
    "print(\"F1-Value:\", round(f1_value_w,4))\n",
    "print(\"Accuracy:\", round(accuracy_w,4))\n",
    "print(\"Sensitivity:\", round(sensitivity_w,4))\n",
    "print(\"Specificity:\", round(specificity_w,4))\n",
    "print(\"AUC:\", round(auc_value_w,4))\n",
    "print(\"Negative Log-Likelihood:\", round(log_li_w,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions_metrics as fm\n",
    "fm.bin_class_report_ontram(y_true, y_pred_binary_w, y_pred_trafo_avg_w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
