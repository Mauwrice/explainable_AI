{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OLD\n",
    "\n",
    "# Version1 = \"10Fold_CIB\" # 10Fold_sigmoid, 10Fold_CIB_V0, 10Fold_CIBLSX\n",
    "# Version2 = \"_V0_M1_avg\" # _V0_M1_avg, _V0_M1\n",
    "# DIR = \"C:/Users/brdd/OneDrive - ZHAW/xAI_stroke/AttentionMaps/\" + Version1 + Version2[:6]\n",
    "# oc_gc = \"oc\" # oc, gc\n",
    "\n",
    "# # heatmaps= np.load(DIR + \"/all_heatmaps_\" + Version1 + Version2[3:] + \"_\" + oc_gc + \"_bothcl.npy\")\n",
    "# heatmaps= np.load(DIR + \"/all_heatmaps_\" + Version1 + Version2[3:] + \"_\" + oc_gc + \"_predcl.npy\")\n",
    "\n",
    "# # meta_dat = pd.read_csv(DIR + \"/all_tab_results_\" + Version1 + Version2 + \".csv\")\n",
    "# meta_dat = pd.read_csv(DIR + \"/all_tab_results_hm_unc_\" + Version1 + Version2[3:] + \"_gc_bothcl.csv\")\n",
    "\n",
    "# meta_dat = meta_dat.sort_values(by=[\"p_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NEW\n",
    "\n",
    "# Define version and directory\n",
    "Version1 = \"CIB\" # CIB, CIBLSX\n",
    "Version2 = \"_M2_wgt\" # _M3_wgt, _M2_wgt\n",
    "DIR = \"C:/Users/brdd/OneDrive - ZHAW/xAI_stroke/AttentionMaps/\" + Version1 + Version2[:3]\n",
    "\n",
    "# chose gradcam or occlusion\n",
    "gc_oc = \"gc\"\n",
    "\n",
    "# Load Data\n",
    "heatmaps= np.load(DIR + \"/all_heatmaps_\" + Version1 + Version2 + \"_\" + gc_oc + \"_predcl_unnormalized.npy\")\n",
    "X = np.load(\"C:/Users/brdd/Documents/x_AI/Data/prepocessed_dicom_3d.npy\")\n",
    "\n",
    "meta_dat = pd.read_csv(DIR + \"/all_tab_results_hm_unc_\" + Version1 + Version2 + \"_\" + gc_oc + \"_predcl_unnormalized.csv\")\n",
    "\n",
    "meta_dat = meta_dat.sort_values(by=[\"p_id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmaps.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.where(meta_dat[\"y_pred_class_avg_w\"] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm1 = np.take(heatmaps, idx, axis = 0).squeeze().mean(axis = 0).mean(axis = 2)\n",
    "plt.imshow(hm1, cmap = \"jet\", vmin = hm1.min(), vmax = hm1.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmaps_norm = []\n",
    "for i in range(heatmaps.shape[0]):\n",
    "    if heatmaps[i].max() == heatmaps[i].min():\n",
    "        hm = np.zeros(heatmaps[i].shape)\n",
    "    else:\n",
    "        hm = (heatmaps[i] - heatmaps[i].min()) / (heatmaps[i].max() - heatmaps[i].min())\n",
    "    heatmaps_norm.append(hm)\n",
    "heatmaps_norm = np.array(heatmaps_norm)\n",
    "\n",
    "hm2 = np.take(np.array(heatmaps_norm), idx, axis = 0).squeeze().mean(axis = 0).mean(axis = 2)\n",
    "plt.imshow(hm2, cmap = \"jet\", vmin = hm2.min(), vmax = hm2.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmaps_sig = []\n",
    "for i in range(heatmaps.shape[0]):\n",
    "    p = meta_dat.y_pred_trafo_avg_w[i]\n",
    "    hm = heatmaps[i] * p * (1-p)\n",
    "    heatmaps_sig.append(hm)\n",
    "heatmaps_sig = np.array(heatmaps_sig)\n",
    "\n",
    "hm3 = np.take(np.array(heatmaps_sig), idx, axis = 0).squeeze().mean(axis = 0).mean(axis = 2)\n",
    "plt.imshow(hm3, cmap = \"jet\", vmin = hm3.min(), vmax = hm3.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## take only favorable or unfavorable cases\n",
    "# heatmaps = heatmaps[meta_dat[\"unfavorable\"] == 0]\n",
    "# meta_dat = meta_dat[meta_dat[\"unfavorable\"] == 0]\n",
    "\n",
    "## take only as favorable or as unfavorable predicted cases\n",
    "# heatmaps = heatmaps[meta_dat[\"y_pred_class_avg\"] == 1]\n",
    "# meta_dat = meta_dat[meta_dat[\"y_pred_class_avg\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmaps_2d = heatmaps.reshape(heatmaps.shape[0], -1)\n",
    "heatmaps_mid = heatmaps[:, :, :, 14, :]\n",
    "heatmaps_avg = np.mean(heatmaps, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(heatmaps_2d.min(), heatmaps_2d.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# Load the pre-trained CNN model\n",
    "model = keras.applications.ResNet50(weights='imagenet', \n",
    "                                 input_shape=(128,128,3),\n",
    "                                 include_top=False)\n",
    "# VGG16, ResNet50, ResNet101\n",
    "\n",
    "# Freeze all backbone layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "print(model.output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_all_layers(heatmap):\n",
    "    # one dimension\n",
    "    if heatmap.shape[3] == 1: \n",
    "        cnn_features = model.predict(np.repeat(heatmap, 3, -1))\n",
    "\n",
    "        # average over the output feature maps\n",
    "        cnn_features = np.mean(cnn_features, axis=(1,2))\n",
    "\n",
    "    # original dimension\n",
    "    elif heatmap.shape[3] == 28:\n",
    "        all_cnn_features = []\n",
    "\n",
    "        for i in range(28):\n",
    "            cnn_features = model.predict(np.repeat(heatmap[:, :, :, i, :], 3, -1))\n",
    "\n",
    "            # average over the output feature maps\n",
    "            all_cnn_features.append(np.mean(cnn_features, axis=(1,2)))\n",
    "\n",
    "        cnn_features = np.moveaxis(np.array(all_cnn_features), source=0, destination=-1)\n",
    "\n",
    "    return cnn_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_features = pred_all_layers(heatmaps_mid)\n",
    "cnn_features = pred_all_layers(heatmaps_avg)\n",
    "# cnn_features = pred_all_layers(heatmaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = cnn_features.reshape(cnn_features.shape[0], -1)\n",
    "\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Perform PCA on features\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "pca_result = pca.fit_transform(features)\n",
    "\n",
    "# Plot the PCA result\n",
    "plt.scatter(pca_result[:, 0], pca_result[:, 1], c=meta_dat['unfavorable'], alpha=0.8)\n",
    "plt.title('PCA Representation of features')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform t-SNE on features\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_result = tsne.fit_transform(features)\n",
    "\n",
    "plt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=meta_dat['unfavorable'], alpha=0.8)\n",
    "# plt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=meta_dat['y_pred_class'], alpha=0.8)\n",
    "plt.title('t-SNE Representation of features')\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "# Perform UMAP on features\n",
    "umap_result = umap.UMAP(n_components=2, random_state=42).fit_transform(features)\n",
    "\n",
    "# Plot the UMAP result\n",
    "plt.scatter(umap_result[:, 0], umap_result[:, 1], c=meta_dat['unfavorable'], alpha=0.8)\n",
    "plt.title('UMAP Representation of features')\n",
    "plt.xlabel('UMAP Dimension 1')\n",
    "plt.ylabel('UMAP Dimension 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "def min_max_norm(x):\n",
    "    return (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "\n",
    "# Compute the coordinates of the image on the plot\n",
    "# adapted from https://learnopencv.com/t-sne-for-feature-visualization/\n",
    "def compute_plot_coordinates(image, x, y):\n",
    "    image_height, image_width, _ = image.shape\n",
    " \n",
    "    # compute the image center coordinates on the plot\n",
    "    center_x = x\n",
    " \n",
    "    # in matplotlib, the y axis is directed upward\n",
    "    # to have the same here, we need to mirror the y coordinate\n",
    "    center_y = y\n",
    " \n",
    "    # knowing the image center,\n",
    "    # compute the coordinates of the top left and bottom right corner\n",
    "    # tl_x = center_x - int(image_width / 2)\n",
    "    # tl_y = center_y - int(image_height / 2)\n",
    "    tl_x = center_x\n",
    "    tl_y = center_y\n",
    " \n",
    "    br_x = tl_x + image_width\n",
    "    br_y = tl_y + image_height\n",
    " \n",
    "    return tl_x, tl_y, br_x, br_y\n",
    "\n",
    "# adapted from: https://stackoverflow.com/questions/43261338/adding-a-border-to-and-image-in-my-code\n",
    "def frame_image(img, frame_width):\n",
    "    b = frame_width # border size in pixel\n",
    "    ny, nx = img.shape[0], img.shape[1] # resolution / number of pixels in x and y\n",
    "    if img.ndim == 3: # rgb or rgba array\n",
    "        framed_img = np.zeros((b+ny+b, b+nx+b, img.shape[2]))\n",
    "    elif img.ndim == 2: # grayscale image\n",
    "        framed_img = np.zeros((b+ny+b, b+nx+b))\n",
    "    framed_img[b:-b, b:-b] = img\n",
    "    return framed_img\n",
    "\n",
    "\n",
    "def plot_image_on_represantion(dim_red_result, maps, meta_info = None,\n",
    "                               pat_ids = None,\n",
    "                               yx_ratio = 1,\n",
    "                               im_size = 128*20, map_col = \"jet\", \n",
    "                               alpha_hm = 0.8, alpha_edge = 0.5, edge_width = 3,\n",
    "                               style=None,\n",
    "                               save_name = None):\n",
    "\n",
    "    dim_red_result[:, 0] = min_max_norm(dim_red_result[:, 0])\n",
    "    dim_red_result[:, 1] = min_max_norm(dim_red_result[:, 1])\n",
    "\n",
    "    dim_red_result = (dim_red_result * (im_size - 128)).astype(int)\n",
    "    if yx_ratio != 1:\n",
    "        dim_red_result[:, 0] = (dim_red_result[:, 0] * yx_ratio).astype(int)\n",
    "\n",
    "    # image = (min_max_norm(mid_maps) * 255).astype(int)\n",
    "    if np.min(maps) < 0:\n",
    "        image = ((maps+1)/2 * 255).astype(int)\n",
    "    else:\n",
    "        image = (maps * 255).astype(int)\n",
    "\n",
    "    # plot   \n",
    "    plot_labels = ('true favorable & predicted favorable', \n",
    "                   'true favorable & predicted unfavorable ', \n",
    "                   'true unfavorable & predicted favorable ', \n",
    "                   'true unfavorable & predicted unfavorable')\n",
    "    plot_colors = (\"limegreen\", \"gold\", \"magenta\", \"red\")\n",
    "\n",
    "    plt.style.use(style)\n",
    "\n",
    "    for i in tqdm(range(dim_red_result.shape[0])):\n",
    "        im = image[i]\n",
    "        tl_x, tl_y, br_x, br_y = compute_plot_coordinates(im, dim_red_result[i, 0], dim_red_result[i, 1])\n",
    "\n",
    "        # plt.imshow(im, extent=(tl_x, br_x, tl_y, br_y), cmap=map_col, alpha = alpha_hm, vmin = (heatmaps[i].min()*255).astype(int), vmax = (heatmaps[i].max()*255).astype(int))\n",
    "        plt.imshow(im, extent=(tl_x, br_x, tl_y, br_y), cmap=map_col, alpha = alpha_hm, vmin = im.min(), vmax = im.max())\n",
    "        # plt.imshow(im, extent=(tl_x, br_x, tl_y, br_y), cmap=map_col, alpha = alpha_hm, vmin = image.min(), vmax = image.max())\n",
    "\n",
    "\n",
    "        if meta_info is not None:\n",
    "            rect = Rectangle((tl_x, tl_y), im.shape[0], im.shape[1], angle=0.0,\n",
    "                  edgecolor = plot_colors[meta_info[i]],\n",
    "                  linewidth=edge_width, facecolor='none', alpha = alpha_edge)\n",
    "            plt.gca().add_patch(rect)\n",
    "\n",
    "        if pat_ids is not None:\n",
    "            plt.text(tl_x, tl_y+(104), pat_ids[i], fontsize=8, color = \"black\")\n",
    "\n",
    "    plt.scatter(dim_red_result[:, 0], dim_red_result[:, 1], s=0.01)\n",
    "    \n",
    "    plt.legend(plot_labels, labelcolor = plot_colors, handlelength=1, handleheight=1, fontsize = 14)\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    leg = ax.get_legend()\n",
    "    for (i, element) in enumerate(leg.legend_handles):\n",
    "        element.set_edgecolor(plot_colors[i])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.axis('off')\n",
    "\n",
    "    if save_name is not None:\n",
    "        plt.savefig(save_name, dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Red and Yellow Rectangles are expected to be near each other.\n",
    "And Green and Pink Rectangles should also be similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "\n",
    "# fav & fav pred 0 => 0, fav & unfav pred => 1, unfav & fav pred => 2, unfav & unfav pred => 3\n",
    "meta_info = list(meta_dat[\"unfavorable\"] * 2 + meta_dat[\"y_pred_class_avg\"])\n",
    "pat_ids = list(meta_dat[\"p_id\"])\n",
    "\n",
    "plot_image_on_represantion(tsne_result, heatmaps_avg, \n",
    "                           meta_info,\n",
    "                           pat_ids = None, # None, pat_ids\n",
    "                           yx_ratio = 1.5,\n",
    "                           im_size = 128*20, map_col = \"jet\", \n",
    "                           alpha_hm = 0.85, alpha_edge = 0.6, \n",
    "                           edge_width = 3,\n",
    "                           style = \"default\", # dark_background, default\n",
    "                           save_name = None, # DIR + \"/tsne_\" + Version1 + Version2 + \"_\" + gc_oc + \"_predcl_unnormalized.png\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the optimal number of clusters using the elbow method\n",
    "wcss = []\n",
    "max_clusters = 10  # Maximum number of clusters to consider\n",
    "for n_clusters in range(1, max_clusters + 1):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init='auto')\n",
    "    kmeans.fit(features)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the within-cluster sum of squares (WCSS) against the number of clusters\n",
    "plt.plot(range(1, max_clusters + 1), wcss)\n",
    "plt.title('Optimal Number of Clusters')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Within-Cluster Sum of Squares (WCSS)')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
