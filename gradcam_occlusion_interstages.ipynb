{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Slider for GradCAM Heatmap\n",
    "\n",
    "Plots an interactive slider for GradCAM heatmaps for all models for a given patient.\n",
    "\n",
    "### Import Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(\"TF  Version\",tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check and set path before loading modules\n",
    "print(os.getcwd())\n",
    "INPUT_DIR = \"/tf/notebooks/schnemau/xAI_stroke_3d/\"\n",
    "OUTPUT_DIR = \"/tf/notebooks/bule/explainable_AI/\"\n",
    "if os.getcwd() != OUTPUT_DIR:\n",
    "    os.chdir(OUTPUT_DIR)\n",
    "    \n",
    "import functions_model_definition as md\n",
    "import functions_read_data as rdat\n",
    "import functions_slider as sl\n",
    "import functions_gradcam as gc\n",
    "import functions_plot_heatmap as phm\n",
    "import functions_metrics as fm\n",
    "import functions_occlusion as oc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Set Up Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ToDo: \n",
    "## - hm_type should always be \"gc\" in this notebook\n",
    "## - pred_hm_only, norm_hm and hm_mode should only be adjusted in last chunk\n",
    "## - pic_save_name is not needed in this notebook: implement dictionary for paths\n",
    "\n",
    "# Define Version\n",
    "version = \"CIB\" # one of:\n",
    "# 10Fold_sigmoid_V0, 10Fold_sigmoid_V1, 10Fold_sigmoid_V2, 10Fold_sigmoid_V2f, 10Fold_sigmoid_V3\n",
    "# 10Fold_softmax_V0, 10Fold_softmax_V1, andrea\n",
    "# 10Fold_CIB, 10Fold_CIBLSX\n",
    "\n",
    "# Define Model Version\n",
    "model_version = 2\n",
    "\n",
    "# define weighting\n",
    "hm_mode = \"wgt\" \n",
    "\n",
    "# define heatmap type\n",
    "hm_type = \"gc\"\n",
    "norm_hm = False # (gradcam is normalized over all heatmaps)\n",
    "pred_hm_only = True\n",
    "\n",
    "# Select naming convention (for CIBLSX model_version >= 3 should be False)\n",
    "comp_mode = False # if True: use old naming convention\n",
    "\n",
    "# define paths\n",
    "DATA_DIR, WEIGHT_DIR, DATA_OUTPUT_DIR, PIC_OUTPUT_DIR, pic_save_name = rdat.dir_setup(\n",
    "    INPUT_DIR, OUTPUT_DIR, version, model_version, \n",
    "    weight_mode = hm_mode, hm_type = hm_type, pred_hm = pred_hm_only, hm_norm = norm_hm,\n",
    "    compatibility_mode=comp_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load images and ids\n",
    "(X_in, pat_ids, id_tab, all_results_tab, pat_orig_tab, pat_norm_tab, num_models) = rdat.version_setup(\n",
    "    DATA_DIR = DATA_DIR, version = version, model_version = model_version,\n",
    "    compatibility_mode=comp_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "(input_dim_img, output_dim, LOSS, layer_connection, last_activation) = md.model_setup(version)\n",
    "\n",
    "model_3d = md.model_init(\n",
    "    version = version, \n",
    "    output_dim = output_dim,\n",
    "    LOSS = LOSS,\n",
    "    layer_connection = layer_connection,\n",
    "    last_activation = last_activation,\n",
    "    C = 2,\n",
    "    learning_rate = 5*1e-5,\n",
    "    batch_size = 6,\n",
    "    input_dim = input_dim_img,\n",
    "    input_dim_tab = pat_norm_tab.drop(columns=[\"p_id\"]).shape[1] if \"LSX\" in version else None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model Name\n",
    "generate_model_name = md.set_generate_model_name(\n",
    "    model_version = model_version, \n",
    "    layer_connection = layer_connection, \n",
    "    last_activation = last_activation, \n",
    "    path = WEIGHT_DIR,\n",
    "    compatability_mode=comp_mode)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ids = [297]\n",
    "(res_table, res_images, res_model_names, res_norm_table) = gc.get_img_and_models(\n",
    "    p_ids, results = all_results_tab, pats = pat_ids, imgs = X_in, \n",
    "    gen_model_name = generate_model_name, norm_tab = pat_norm_tab,\n",
    "    num_models = num_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cl = \"y_pred_class_avg_w\"\n",
    "pred_co = \"pred_correct_w\"\n",
    "y_pred_prob = \"y_pred_trafo_avg_w\"\n",
    "y_pred_u = \"y_pred_unc_w\"\n",
    "\n",
    "invert_hm = \"all\" if res_table[y_pred_cl][0] == 0 else \"none\"\n",
    "pos_hm = \"last\"\n",
    "cmap = \"jet\"\n",
    "hm_positive=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(image, minima, maxima):\n",
    "    plt.figure()\n",
    "    plt.imshow(image, cmap='jet', vmin = minima, vmax = maxima, alpha=0.4) # jet / gray, alpha 0.4 / 1\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "\n",
    "avg_image = np.mean(res_images[0], axis = 2).squeeze()\n",
    "plot_img(avg_image, np.min(avg_image), np.max(avg_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradCam\n",
    "\n",
    "Ensemble GradCam first as comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap, resized_img, max_hm_slice, hm_mean_std, all_heatmaps = gc.multi_models_grad_cam_3d(\n",
    "            img = np.expand_dims(res_images[0], axis = 0), \n",
    "            cnn = model_3d,\n",
    "            model_names = res_model_names[0],\n",
    "            layers = md.get_last_conv_layer(model_3d),\n",
    "            model_mode = \"weighted\",\n",
    "            pred_index = 0,\n",
    "            invert_hm = invert_hm,\n",
    "            pos_hm = pos_hm,\n",
    "            # model weigths are only used when model_mode = \"weighted\"\n",
    "            model_weights = res_table[0:1].reset_index(drop = True).loc[:, \n",
    "                res_table.columns.str.startswith(\"weight\")].to_numpy().squeeze(),\n",
    "            tabular_df = res_norm_table,\n",
    "            normalize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phm.plot_heatmap(resized_img, heatmap,\n",
    "                version = \"overlay\",\n",
    "                mode = \"avg\",\n",
    "                hm_colormap=cmap,\n",
    "                hm_positive=hm_positive,\n",
    "                colorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now GradCam for one model with all needed intermediate steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3d_0 = model_3d\n",
    "model_3d_0.load_weights(res_model_names[0][0])\n",
    "\n",
    "img = np.expand_dims(res_images[0], axis = 0),\n",
    "model_3d = model_3d_0\n",
    "layer = md.get_last_conv_layer(model_3d)\n",
    "normalize = False\n",
    "pred_index=None\n",
    "inv_hm=False\n",
    "relu_hm=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_3d.name == \"cnn_3d_\":\n",
    "    grad_model = tf.keras.models.Model([model_3d.inputs], \n",
    "        [model_3d.get_layer(layer).output, model_3d.output])\n",
    "elif model_3d.name == \"mod_ontram\":\n",
    "    grad_model = tf.keras.models.Model([model_3d.inputs], \n",
    "        [model_3d.get_layer(layer).output, model_3d.get_layer(\"dense_complex_intercept\").output])\n",
    "        \n",
    "with tf.GradientTape() as tape:\n",
    "    conv_outputs, predictions = grad_model(img)\n",
    "    # check for right model variant\n",
    "    if model_3d.name == \"mod_ontram\":\n",
    "        pred_index = 0\n",
    "        predictions = predictions * -1 # ontram predicts cumulative dist therfore invert\n",
    "    elif pred_index is None or model_3d.layers[-1].get_config().get(\"activation\") == \"sigmoid\":\n",
    "        pred_index = tf.argmax(predictions[0])\n",
    "    class_channel = predictions[:, pred_index] # when sigmoid, pred_index must be None or 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = tape.gradient(class_channel, conv_outputs)[0]\n",
    "\n",
    "if model_3d.name == \"mod_ontram\" and not isinstance(model_3d.input, list):\n",
    "    # output of CNN can be used for predictions\n",
    "    grads = fm.sigmoid(predictions) * (1 - fm.sigmoid(predictions)) * grads # sigmoid gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_grad_maps = tf.reduce_mean(grads, axis=2).numpy()\n",
    "\n",
    "for i in [0,1,2,3,-1]:\n",
    "    plot_img(avg_grad_maps[:,:,i], np.min(avg_grad_maps), np.max(avg_grad_maps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.reduce_mean(grads, axis=(0, 1, 2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = conv_outputs[0]   \n",
    "heatmap = output @ weights[..., tf.newaxis]\n",
    "heatmap = tf.squeeze(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_original_size_hm = tf.reduce_mean(heatmap, axis=2).numpy()\n",
    "plot_img(avg_original_size_hm, np.min(avg_original_size_hm), np.max(avg_original_size_hm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_original_size_hm_relu = tf.reduce_mean(heatmap, axis=2).numpy()\n",
    "plot_img(avg_original_size_hm_relu, np.min(avg_original_size_hm_relu), np.max(avg_original_size_hm_relu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "heatmap = resize(heatmap.numpy(), img[0].shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_finish = tf.reduce_mean(heatmap, axis=2).numpy().squeeze()\n",
    "plot_img(avg_finish, np.min(avg_finish), np.max(avg_finish))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Occlusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_size = (18, 18, 4)\n",
    "occ_stride = (10, 10, 3)\n",
    "\n",
    "invert_hm = \"pred_class\"\n",
    "both_directions = False\n",
    "cmap = \"jet\"\n",
    "hm_positive=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(heatmap, resized_img, max_hm_slice, hm_mean_std, all_heatmaps) =  oc.volume_occlusion(\n",
    "            volume = res_images, \n",
    "            res_tab = res_table, \n",
    "            occlusion_size = np.array(occ_size), \n",
    "            cnn = model_3d,\n",
    "            invert_hm=invert_hm,\n",
    "            tabular_df=res_norm_table,\n",
    "            model_mode = \"weighted\",\n",
    "            both_directions=both_directions,\n",
    "            model_names = res_model_names[0],\n",
    "            normalize = False,\n",
    "            occlusion_stride = occ_stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phm.plot_heatmap(resized_img, heatmap,\n",
    "                version = \"overlay\",\n",
    "                mode = \"avg\",\n",
    "                hm_colormap=cmap,\n",
    "                hm_positive=hm_positive,\n",
    "                colorbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0,1,2,3,4,6,13,20,-1]:\n",
    "    hm = heatmap[:,:,i,0]\n",
    "    plot_img(hm, np.min(hm), np.max(hm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm_avg = np.mean(heatmap, axis = 2).squeeze()\n",
    "plot_img(hm_avg, np.min(hm_avg), np.max(hm_avg))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
