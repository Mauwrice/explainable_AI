{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.utils import to_categorical\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(\"TF  Version\",tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check and set path before loading modules\n",
    "print(os.getcwd())\n",
    "INPUT_DIR = \"/tf/notebooks/schnemau/xAI_stroke_3d/\"\n",
    "OUTPUT_DIR = \"/tf/notebooks/bule/explainable_AI/\"\n",
    "if os.getcwd() != OUTPUT_DIR:\n",
    "    os.chdir(OUTPUT_DIR)\n",
    "    print(os.getcwd())\n",
    "\n",
    "import functions_metrics as fm\n",
    "import functions_model_definition as md\n",
    "import functions_read_data as rdat \n",
    "import Utils_maurice as utils\n",
    "import functions_gradcam as gc\n",
    "import functions_plot_heatmap as phm\n",
    "\n",
    "#ontram functions\n",
    "from k_ontram_functions.ontram import ontram\n",
    "from k_ontram_functions.ontram_loss import ontram_loss\n",
    "from k_ontram_functions.ontram_metrics import ontram_acc, ontram_auc\n",
    "from k_ontram_functions.ontram_predict import predict_ontram, get_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"10Fold_CIB\"  # 10Fold_CIBLSX, 10Fold_CIB\n",
    "layer_connection = \"globalAveragePooling\" \n",
    "last_activation = \"linear\" \n",
    "# Define Model Version\n",
    "model_version = 1\n",
    "\n",
    "# should csv be saved?\n",
    "save_file = False\n",
    "\n",
    "DATA_OUTPUT_DIR = OUTPUT_DIR + \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the paths for the result assembly\n",
    "DATA_DIR = INPUT_DIR + \"data/\" \n",
    "WEIGHT_DIR = INPUT_DIR + \"weights/\" + version + \"/\"\n",
    "id_tab = pd.read_csv(DATA_DIR + \"10Fold_ids_V0.csv\", sep=\",\")\n",
    "X = np.load(DATA_DIR + \"prepocessed_dicom_3d.npy\")\n",
    "all_result_name = \"all_tab_results_\" + version + \"_M\" + str(model_version)\n",
    "which_splits = list(range(0,10)) # 10 Fold\n",
    "print(id_tab.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_valid, X_test),(X_tab_train, X_tab_valid, X_tab_test), (y_train, y_valid, y_test) = rdat.split_data_tabular(\n",
    "    id_tab, X, 1)\n",
    "\n",
    "input_dim = (128, 128, 28, 1)\n",
    "output_dim = 1\n",
    "batch_size = 6\n",
    "C = 2 \n",
    "\n",
    "mbl = utils.img_model_linear_final(input_dim, output_dim)\n",
    "if version == \"10Fold_CIBLSX\":\n",
    "    mls = utils.mod_linear_shift(X_tab_train.shape[1])\n",
    "    model_3d = ontram(mbl, mls)\n",
    "else:\n",
    "    model_3d = ontram(mbl)             \n",
    "\n",
    "model_3d.compile(optimizer=keras.optimizers.Adam(learning_rate=5*1e-5),\n",
    "                                loss=ontram_loss(C, batch_size),\n",
    "                                metrics=[ontram_acc(C, batch_size)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = (\"/tf/notebooks/schnemau/xAI_stroke_3d/weights/\" + version + \"/3d_cnn_binary_model_split\" + \n",
    "    (\"CIB_LSX\" if version == \"10Fold_CIBLSX\" else \"\") + str(1) + \n",
    "    (\"_normalized\" if version == \"10Fold_CIBLSX\" else \"_unnormalized\") +\n",
    "    \"_avg_layer_paper_model_\" + last_activation + \"_activation_\" + str(1) + \"_\" + str(1) + \".h5\")        \n",
    "\n",
    "model_3d.load_weights(model_name)        \n",
    "test_data = tf.data.Dataset.from_tensor_slices((X_test, X_tab_test))\n",
    "test_labels = tf.data.Dataset.from_tensor_slices((to_categorical(y_test)))\n",
    "test_loader = tf.data.Dataset.zip((test_data, test_labels))\n",
    "test_dataset_pred = (test_loader.batch(len(X_test)))\n",
    "predic =  predict_ontram(model_3d, data = test_dataset_pred)['pdf'][:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_num = 10\n",
    "\n",
    "# ht, im = gc.ontram_grad_cam_3d(X_test[id_num:id_num+1], model_3d, \"conv3d_3\", \"dense_complex_intercept\")\n",
    "ht, im = gc.grad_cam_3d(X_test[id_num:id_num+1], model_3d, \"conv3d_3\", gcplusplus=True, inv_hm = True)\n",
    "\n",
    "print(\"p_id:\", id_tab[id_tab.fold1 == \"test\"].p_id.iloc[id_num])\n",
    "print(\"unfavorable:\", id_tab[id_tab.fold1 == \"test\"].unfavorable.iloc[id_num])\n",
    "print(\"prediction:\", 1-predic[id_num])\n",
    "phm.plot_heatmap(im, ht,\n",
    "            version = \"overlay\",\n",
    "            mode = \"avg\",\n",
    "            hm_colormap=\"jet\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
