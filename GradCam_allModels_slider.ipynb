{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF  Version 2.4.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(\"TF  Version\",tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf\n"
     ]
    }
   ],
   "source": [
    "# check and set path before loading modules\n",
    "print(os.getcwd())\n",
    "DIR = \"/tf/notebooks/brdd/xAI_stroke_3d/\"\n",
    "if os.getcwd() != DIR:\n",
    "    os.chdir(DIR)\n",
    "    \n",
    "import functions_metrics as fm\n",
    "import functions_read_data as rdat\n",
    "import function_model_definition as md\n",
    "import functions_gradcam as gc\n",
    "import functions_plot_heatmap as fph"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path + output path:\n",
    "DATA_DIR = DIR + \"data/\"\n",
    "\n",
    "version = \"10Fold_sigmoid_V0\" # one of:\n",
    "# 10Fold_sigmoid_V0, 10Fold_sigmoid_V1, 10Fold_sigmoid_V2, 10Fold_sigmoid_V2f, 10Fold_sigmoid_V3\n",
    "# 10Fold_softmax_V0, 10Fold_softmax_V1, andrea\n",
    "save_plot = False\n",
    "\n",
    "# Define Model Version\n",
    "model_version = 1\n",
    "\n",
    "if version.startswith(\"10Fold\"):\n",
    "    WEIGHT_DIR = DIR + \"weights/\" + version + \"/\"\n",
    "    OUTPUT_DIR = DIR + \"pictures/\" + version + \"/\"\n",
    "    pic_save_name = \"10Fold_ensembling\" + version[6:]\n",
    "    \n",
    "elif version == \"andrea\":\n",
    "    WEIGHT_DIR = DIR + \"weights/andrea_split/\"\n",
    "    OUTPUT_DIR = DIR + \"pictures/andrea_split/\"\n",
    "    pic_save_name = \"andrea_split\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load images and ids\n",
    "\n",
    "if version == \"andrea\": ## for andrea\n",
    "    with h5py.File(\"/tf/notebooks/hezo/stroke_zurich/data/dicom_2d_192x192x3_clean_interpolated_18_02_2021_preprocessed2.h5\", \"r\") as h5:\n",
    "        # with h5py.File(IMG_DIR2 + 'dicom-3d.h5', \"r\") as h5:\n",
    "        # both images are the same\n",
    "            X_in = h5[\"X\"][:]\n",
    "            pat = h5[\"pat\"][:]\n",
    "            \n",
    "    # load results\n",
    "    path_results = DATA_DIR + \"all_tab_results_andrea_split.csv\" # andrea split\n",
    "    \n",
    "elif version.startswith(\"10Fold\"): ## for 10 Fold       \n",
    "    if version.endswith(\"V0\") or version.endswith(\"sigmoid\"):\n",
    "        id_tab = pd.read_csv(DATA_DIR + \"10Fold_ids_V0.csv\", sep=\",\")\n",
    "        num_models = 5\n",
    "    elif version.endswith(\"V1\"):\n",
    "        id_tab = pd.read_csv(DATA_DIR + \"10Fold_ids_V1.csv\", sep=\",\")\n",
    "        num_models = 10\n",
    "    elif version.endswith(\"V2\") or version.endswith(\"V2f\"):\n",
    "        id_tab = pd.read_csv(DATA_DIR + \"10Fold_ids_V2.csv\", sep=\",\")\n",
    "        num_models = 5\n",
    "    elif version.endswith(\"V3\"):\n",
    "        id_tab = pd.read_csv(DATA_DIR + \"10Fold_ids_V3.csv\", sep=\",\")\n",
    "        num_models = 5\n",
    "    pat = id_tab[\"p_id\"].to_numpy()\n",
    "    X_in = np.load(DATA_DIR + \"prepocessed_dicom_3d.npy\")\n",
    "    \n",
    "    # load results\n",
    "    path_results = DATA_DIR + \"all_tab_results_\" + version + \"_M\" + str(model_version) + \".csv\" # 10 Fold\n",
    "\n",
    "all_results = pd.read_csv(path_results, sep=\",\")\n",
    "all_results = all_results.sort_values(\"p_idx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_id</th>\n",
       "      <th>mrs3</th>\n",
       "      <th>age</th>\n",
       "      <th>sexm</th>\n",
       "      <th>nihss_baseline</th>\n",
       "      <th>mrs_before</th>\n",
       "      <th>stroke_beforey</th>\n",
       "      <th>tia_beforey</th>\n",
       "      <th>ich_beforey</th>\n",
       "      <th>rf_hypertoniay</th>\n",
       "      <th>rf_diabetesy</th>\n",
       "      <th>rf_hypercholesterolemiay</th>\n",
       "      <th>rf_smokery</th>\n",
       "      <th>rf_atrial_fibrillationy</th>\n",
       "      <th>rf_chdy</th>\n",
       "      <th>eventtia</th>\n",
       "      <th>iaty</th>\n",
       "      <th>ivty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>85,6</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>66,7</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>29,2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>6</td>\n",
       "      <td>89,2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>540</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>541</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>542</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>543</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>544</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>518 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     p_id  mrs3   age  sexm  nihss_baseline  mrs_before  stroke_beforey  \\\n",
       "0     101     1  85,6     0             9.0         3.0             0.0   \n",
       "1     102     1  66,7     1             NaN         1.0             0.0   \n",
       "2     103     0  29,2     0             0.0         0.0             0.0   \n",
       "3     104     0    83     1             0.0         0.0             0.0   \n",
       "4     105     6  89,2     0             0.0         0.0             0.0   \n",
       "..    ...   ...   ...   ...             ...         ...             ...   \n",
       "513   540     2    80     0             7.0         0.0             0.0   \n",
       "514   541     0    19     1            10.0         0.0             0.0   \n",
       "515   542     1    68     1             3.0         0.0             0.0   \n",
       "516   543     4    74     0             4.0         0.0             NaN   \n",
       "517   544     1    44     1             4.0         0.0             0.0   \n",
       "\n",
       "     tia_beforey  ich_beforey  rf_hypertoniay  rf_diabetesy  \\\n",
       "0            0.0          0.0             1.0           0.0   \n",
       "1            0.0          0.0             0.0           0.0   \n",
       "2            0.0          0.0             0.0           0.0   \n",
       "3            0.0          0.0             0.0           1.0   \n",
       "4            0.0          0.0             1.0           0.0   \n",
       "..           ...          ...             ...           ...   \n",
       "513          0.0          0.0             1.0           0.0   \n",
       "514          0.0          0.0             0.0           0.0   \n",
       "515          0.0          0.0             1.0           1.0   \n",
       "516          NaN          NaN             NaN           NaN   \n",
       "517          0.0          0.0             0.0           0.0   \n",
       "\n",
       "     rf_hypercholesterolemiay  rf_smokery  rf_atrial_fibrillationy  rf_chdy  \\\n",
       "0                         0.0         0.0                      0.0      1.0   \n",
       "1                         0.0         1.0                      0.0      0.0   \n",
       "2                         0.0         0.0                      0.0      0.0   \n",
       "3                         1.0         0.0                      0.0      0.0   \n",
       "4                         1.0         0.0                      0.0      0.0   \n",
       "..                        ...         ...                      ...      ...   \n",
       "513                       1.0         0.0                      0.0      0.0   \n",
       "514                       0.0         0.0                      0.0      0.0   \n",
       "515                       0.0         0.0                      0.0      0.0   \n",
       "516                       NaN         NaN                      NaN      NaN   \n",
       "517                       0.0         0.0                      0.0      0.0   \n",
       "\n",
       "     eventtia  iaty ivty  \n",
       "0           0   NaN  NaN  \n",
       "1           0   NaN  NaN  \n",
       "2           0   NaN  NaN  \n",
       "3           0   NaN  NaN  \n",
       "4           0   NaN  NaN  \n",
       "..        ...   ...  ...  \n",
       "513         1   0.0    0  \n",
       "514         1   1.0    1  \n",
       "515         1   0.0    0  \n",
       "516         1   0.0    0  \n",
       "517         1   0.0    1  \n",
       "\n",
       "[518 rows x 18 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load patient data\n",
    "PAT_CSV_DIR = \"/tf/notebooks/hezo/stroke_zurich/data/baseline_data_zurich_prepared0.csv\" \n",
    "pat_dat = pd.read_csv(PAT_CSV_DIR, sep=\";\")\n",
    "pat_dat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "input_dim = (128, 128, 28, 1)\n",
    "\n",
    "if \"sigmoid\" in version or \"andrea_split\" in version:\n",
    "    last_activation = \"sigmoid\"\n",
    "    output_dim = 1\n",
    "    LOSS = \"binary_crossentropy\"\n",
    "elif \"softmax\" in version:\n",
    "    last_activation = \"softmax\"\n",
    "    output_dim = 2\n",
    "    LOSS = tf.keras.losses.categorical_crossentropy\n",
    "    \n",
    "if version.endswith(\"f\"):\n",
    "    layer_connection = \"flatten\"\n",
    "else:\n",
    "    layer_connection = \"globalAveragePooling\"\n",
    "\n",
    "model_3d = md.stroke_binary_3d(input_dim = input_dim,\n",
    "                               output_dim = output_dim,\n",
    "                               layer_connection = layer_connection,\n",
    "                               last_activation = last_activation)\n",
    "model_3d.compile(\n",
    "    loss=LOSS,\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=5*1e-5),\n",
    "    metrics=[\"acc\", tf.keras.metrics.AUC()]\n",
    ")\n",
    "\n",
    "# define if print should be enabled\n",
    "check_print = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model Name\n",
    "def generate_model_name(which_split, model_nr, model_version = model_version, path = WEIGHT_DIR):\n",
    "    if layer_connection == \"globalAveragePooling\":\n",
    "        return (path + \"3d_cnn_binary_model_split\" + str(which_split) + \n",
    "                  \"_unnormalized_avg_layer_paper_model_\" + last_activation + \"_activation_\"  + str(model_version) + str(model_nr) + \".h5\")\n",
    "    elif layer_connection == \"flatten\":\n",
    "        return (path + \"3d_cnn_binary_model_split\" + str(which_split) + \n",
    "                  \"_unnormalized_flat_layer_paper_model_\" + last_activation + \"_activation_\" + str(model_version) + str(model_nr) + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_layers = [i.name for i in model_3d.layers[1:-6]]\n",
    "vis_layers = [vis_layer for vis_layer in vis_layers if vis_layer.startswith(\"conv\")]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradCam Slider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, HBox, VBox, Layout, AppLayout\n",
    "from IPython.display import display\n",
    "from termcolor import colored\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from importlib import reload\n",
    "reload(pgc)\n",
    "reload(gc)\n",
    "\n",
    "def gradcam_interactive_plot(p_id, pred_hm_only=True):\n",
    "    p_ids = [p_id]\n",
    "    (res_table, res_images, res_model_names) = gc.get_img_and_models(\n",
    "        p_ids, results = all_results, pats = pat, imgs = X_in, \n",
    "        gen_model_name = generate_model_name,\n",
    "        num_models = num_models)\n",
    "    \n",
    "    print(\"patient id: \", res_table.p_id[0])\n",
    "    print(\"age: \", pat_dat[pat_dat[\"p_id\"] == res_table.p_id[0]][\"age\"].values[0])\n",
    "    print(\"true mrs: \", res_table.mrs[0])\n",
    "    print(\"true class: \", res_table.unfavorable[0])\n",
    "    print(colored(\"pred class: \"+str(res_table.y_pred_class[0]), \n",
    "                'green' if res_table[\"pred_correct\"][0] == True else 'red'))\n",
    "    print(\"pred prob (class 1): \", res_table.y_pred_trafo_avg[0])\n",
    "    print(\"pred uncertainty: \", res_table.y_pred_unc[0])\n",
    "    # print(\"heatmap unc. last layer: \", res_table.y_pred_unc[0])\n",
    "    \n",
    "    ## Generate heatmap\n",
    "    if pred_hm_only:\n",
    "        invert_hm = \"all\" if res_table.y_pred_class[0] == 0 else \"none\"\n",
    "        gcpp_hm = \"last\"\n",
    "        cmap = \"jet\"\n",
    "        hm_positive=True\n",
    "    else:\n",
    "        invert_hm = \"none\"\n",
    "        gcpp_hm = \"none\"\n",
    "        cmap = \"bwr\"\n",
    "        hm_positive=False\n",
    "    \n",
    "            \n",
    "    heatmap, resized_img, max_hm_slice, hm_mean_std = gc.multi_models_grad_cam_3d(\n",
    "        img = np.expand_dims(res_images[0], axis = 0), \n",
    "        cnn = model_3d,\n",
    "        model_names = res_model_names[0],\n",
    "        layers = vis_layers[3],\n",
    "        model_mode = \"mean\",\n",
    "        pred_index = 0,\n",
    "        invert_hm = invert_hm,\n",
    "        gcpp_hm = gcpp_hm)\n",
    "\n",
    "    slices = np.unravel_index(heatmap.argmax(), heatmap.shape)\n",
    "    print(\"max slices:\", (slices[2], slices[0], slices[1]))\n",
    "    \n",
    "    ## Plot Heatmap Average\n",
    "    fph.plot_gradcam(resized_img, heatmap,\n",
    "                version = \"overlay\",\n",
    "                mode = \"avg\",\n",
    "                hm_colormap=cmap,\n",
    "                hm_positive=hm_positive,\n",
    "                colorbar=True)\n",
    "\n",
    "    ## Plot Heatmap Slider\n",
    "    def slicer(axi_slider, cor_slider, sag_slider):\n",
    "        fph.plot_gradcam(resized_img, heatmap,\n",
    "                version = \"overlay\",\n",
    "                mode = \"def\",\n",
    "                slices = (cor_slider,sag_slider,axi_slider),\n",
    "                hm_colormap=cmap,\n",
    "                hm_positive=hm_positive,\n",
    "                colorbar=True)\n",
    "        fph.plot_gradcam(resized_img, heatmap,\n",
    "                version = \"original\",\n",
    "                mode = \"def\",\n",
    "                slices=(cor_slider,sag_slider,axi_slider),\n",
    "                hm_colormap=cmap,\n",
    "                hm_positive=hm_positive,\n",
    "                slice_line=True)\n",
    "\n",
    "    w=interactive(\n",
    "        slicer, \n",
    "        axi_slider=widgets.IntSlider(value=slices[2],min=0,max=27,step=1), \n",
    "        cor_slider=widgets.IntSlider(value=slices[0],min=0,max=127,step=1), \n",
    "        sag_slider=widgets.IntSlider(value=slices[1],min=0,max=127,step=1))\n",
    "\n",
    "    slider_layout = Layout(display='flex', flex_flow='row', \n",
    "                        justify_content='space-between', align_items='center',\n",
    "                        width='9.2in')\n",
    "    images_layout = Layout(display='flex', flex_flow='row', \n",
    "                        justify_content='space-between', align_items='center',\n",
    "                        width='15', height='15')\n",
    "\n",
    "    display(VBox([\n",
    "        HBox([w.children[0],w.children[1], w.children[2]], layout=slider_layout),\n",
    "        HBox([w.children[3]], layout=images_layout)\n",
    "    ]))      \n",
    "    w.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  485\n",
      "age:  89\n",
      "true mrs:  4.0\n",
      "true class:  1\n",
      "\u001b[32mpred class: 1\u001b[0m\n",
      "pred prob (class 1):  0.5186191\n",
      "pred uncertainty:  0.22075641\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[1,32,128,128,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv3D]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1f6a2d97ead1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgradcam_interactive_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m485\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_hm_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-5a900eed488c>\u001b[0m in \u001b[0;36mgradcam_interactive_plot\u001b[0;34m(p_id, pred_hm_only)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mpred_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0minvert_hm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minvert_hm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         gcpp_hm = gcpp_hm)\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munravel_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheatmap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tf/notebooks/brdd/xAI_stroke_3d/functions_gradcam.py\u001b[0m in \u001b[0;36mmulti_models_grad_cam_3d\u001b[0;34m(img, cnn, model_names, layers, model_mode, layer_mode, normalize, pred_index, invert_hm, gcpp_hm)\u001b[0m\n\u001b[1;32m    149\u001b[0m         heatmap, resized_img = multi_layers_grad_cam_3d(\n\u001b[1;32m    150\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_3d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             pred_index=pred_index, invert_hm=invert_hm, gcpp_hm=gcpp_hm)\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0mh_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tf/notebooks/brdd/xAI_stroke_3d/functions_gradcam.py\u001b[0m in \u001b[0;36mmulti_layers_grad_cam_3d\u001b[0;34m(img, model_3d, layers, mode, normalize, pred_index, invert_hm, gcpp_hm)\u001b[0m\n\u001b[1;32m    103\u001b[0m             heatmap, resized_img = grad_cam_3d(\n\u001b[1;32m    104\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_3d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_3d\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                 pred_index=pred_index, inv_hm=False, gcplusplus=gcpp)\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mh_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tf/notebooks/brdd/xAI_stroke_3d/functions_gradcam.py\u001b[0m in \u001b[0;36mgrad_cam_3d\u001b[0;34m(img, model_3d, layer, pred_index, inv_hm, gcplusplus)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# with respect to the activations of the last conv layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mconv_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpred_index\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmodel_3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"activation\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mpred_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \"\"\"\n\u001b[1;32m    424\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 425\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_v2\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1018\u001b[0m       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m       \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m       name=name)\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_internal\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[1;32m   1148\u001b[0m           \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m           \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m   1151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mchannel_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m_conv3d_expanded_batch\u001b[0;34m(input, filter, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   3016\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3017\u001b[0m         \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3018\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   3019\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3020\u001b[0m     return squeeze_batch_dims(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv3d\u001b[0;34m(input, filter, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1398\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1400\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1401\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1,32,128,128,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv3D]"
     ]
    }
   ],
   "source": [
    "gradcam_interactive_plot(485, pred_hm_only=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
