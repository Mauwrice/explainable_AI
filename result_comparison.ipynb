{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Results of the Binary Python Model to the Original R Folds as in the paper\n",
    "\n",
    "Plot the AUC of all 5 ensemble (only weights differ) of the split 6 from the paper (andrea).   \n",
    "Compare the results to the original one achieved with R. Amongst others with a calibration plot.\n",
    "\n",
    "## Load Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from scipy import ndimage\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "print(\"TF  Version\",tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check and set path before loading modules\n",
    "print(os.getcwd())\n",
    "DIR = \"/tf/notebooks/brdd/xAI_stroke_3d/\"\n",
    "if os.getcwd() != DIR:\n",
    "    os.chdir(DIR)\n",
    "\n",
    "import functions_metrics as fm\n",
    "import functions_model_definition as md\n",
    "\n",
    "print(\"TF  Version\",tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path + output path:\n",
    "print(os.getcwd())\n",
    "IMG_DIR = \"/tf/notebooks/hezo/stroke_zurich/data/\" \n",
    "# IMG_DIR2 = \"/tf/notebooks/kook/data-sets/stroke-lh/\"\n",
    "DATA_DIR = \"/tf/notebooks/hezo/stroke_zurich/data/\" \n",
    "WEIGHT_DIR = \"/tf/notebooks/brdd/xAI_stroke_3d/weights/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"3d_cnn_binary_model_split6_unnormalized_avg_layer_paper_model_sigmoid_activation_\"\n",
    "\n",
    "layer_connection = \"globalAveragePooling\"\n",
    "last_activation = \"sigmoid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(IMG_DIR + 'dicom_2d_192x192x3_clean_interpolated_18_02_2021_preprocessed2.h5', \"r\") as h5:\n",
    "# with h5py.File(IMG_DIR2 + 'dicom-3d.h5', \"r\") as h5:\n",
    "# both images are the same\n",
    "    X_in = h5[\"X\"][:]\n",
    "    Y_img = h5[\"Y_img\"][:]\n",
    "    Y_pat = h5[\"Y_pat\"][:]\n",
    "    pat = h5[\"pat\"][:]\n",
    "    \n",
    "X_in = np.expand_dims(X_in, axis = 4)\n",
    "print(X_in.shape, X_in.min(), X_in.max(), X_in.mean(), X_in.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv(IMG_DIR + 'baseline_data_zurich_prepared.csv', sep=\",\")\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "andrea_splits = pd.read_csv('/tf/notebooks/brdd/xAI_stroke_3d/data/andrea_splits.csv', \n",
    "                            sep='\\,', header = None, engine = 'python', \n",
    "                            usecols = [1,2,3]).apply(lambda x: x.str.replace(r\"\\\"\",\"\"))\n",
    "andrea_splits.columns = andrea_splits.iloc[0]\n",
    "andrea_splits.drop(index=0, inplace=True)\n",
    "andrea_splits = andrea_splits.astype({'idx': 'int32', 'spl': 'int32'})\n",
    "split6 = andrea_splits.loc[andrea_splits['spl']==6]\n",
    "split6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = []\n",
    "for p in pat:\n",
    "    if p in dat.p_id.values:\n",
    "        n.append(p)\n",
    "n = len(n)\n",
    "\n",
    "# match image and tabular data\n",
    "X = np.zeros((n, X_in.shape[1], X_in.shape[2], X_in.shape[3], X_in.shape[4]))\n",
    "X_tab = np.zeros((n, 13))\n",
    "Y_mrs = np.zeros((n))\n",
    "Y_eventtia = np.zeros((n))\n",
    "p_id = np.zeros((n))\n",
    "\n",
    "i = 0\n",
    "for j, p in enumerate(pat):\n",
    "    if p in dat.p_id.values:\n",
    "        k = np.where(dat.p_id.values == p)[0]\n",
    "        X_tab[i,:] = dat.loc[k,[\"age\", \"sexm\", \"nihss_baseline\", \"mrs_before\",\n",
    "                               \"stroke_beforey\", \"tia_beforey\", \"ich_beforey\", \n",
    "                               \"rf_hypertoniay\", \"rf_diabetesy\", \"rf_hypercholesterolemiay\", \n",
    "                               \"rf_smokery\", \"rf_atrial_fibrillationy\", \"rf_chdy\"]]\n",
    "        X[i] = X_in[j]\n",
    "        p_id[i] = pat[j]\n",
    "        Y_eventtia[i] = Y_pat[j]\n",
    "        Y_mrs[i] = dat.loc[k, \"mrs3\"]\n",
    "        i += 1\n",
    "X_tab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_new = []\n",
    "for element in Y_mrs:\n",
    "    if element in [0,1,2]:\n",
    "        Y_new.append(0)\n",
    "    else:\n",
    "        Y_new.append(1)\n",
    "Y_new = np.array(Y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training set and test set \"split6\"\n",
    "\n",
    "X = np.squeeze(X)\n",
    "X = np.float32(X)\n",
    "\n",
    "train_idx = split6[\"idx\"][split6['type'] == \"train\"].to_numpy() -1 \n",
    "valid_idx = split6[\"idx\"][split6['type'] == \"val\"].to_numpy() - 1 \n",
    "test_idx = split6[\"idx\"][split6['type'] == \"test\"].to_numpy() - 1 \n",
    "\n",
    "X_train = X[train_idx]\n",
    "# y_train = Y_eventtia[train_idx]\n",
    "y_train = Y_new[train_idx]\n",
    "X_valid = X[valid_idx]\n",
    "# y_valid = Y_eventtia[valid_idx]\n",
    "y_valid = Y_new[valid_idx]\n",
    "X_test = X[test_idx]\n",
    "# y_test = Y_eventtia[test_idx]\n",
    "y_test = Y_new[test_idx]\n",
    "\n",
    "print(X_train.shape, X_valid.shape, X_test.shape)\n",
    "print(y_train.shape, y_valid.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = np.expand_dims(X_train, axis = -1).shape[1:]\n",
    "output_dim = 1\n",
    "\n",
    "# call model\n",
    "model_3d = md.stroke_binary_3d(input_dim = input_dim,\n",
    "                               output_dim = output_dim,\n",
    "                               layer_connection = layer_connection,\n",
    "                               last_activation = last_activation)\n",
    "model_3d.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3d.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=5*1e-5),\n",
    "    metrics=[\"acc\", tf.keras.metrics.AUC()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results per Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check first for one model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3d.load_weights(WEIGHT_DIR + \"andrea_split/\" + model_name + \"14\" + \".h5\")\n",
    "# model_3d.evaluate(x=X_test, y=y_test)\n",
    "# y_pred = model_3d.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3d.evaluate(x=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over all models and save the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_endings = [\"10\", \"11\", \"12\", \"13\", \"14\"]\n",
    "y_preds = []\n",
    "fprs = []\n",
    "tprs = []\n",
    "aucs = []\n",
    "cal_plot_datas = []\n",
    "\n",
    "# ROC-Curve\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "\n",
    "for model_ending in model_endings:\n",
    "    model_3d.load_weights(WEIGHT_DIR + \"andrea_split/\" + model_name + model_ending + \".h5\")\n",
    "    y_pred = model_3d.predict(X_test)\n",
    "    y_preds.append(y_pred)\n",
    "    \n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, (y_pred))\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    fprs.append(fpr)\n",
    "    tprs.append(tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    \n",
    "    plt.plot(fpr, tpr, label = 'AUC = %0.2f' % roc_auc)\n",
    "    \n",
    "    cal_plot_datas.append(\n",
    "        fm.cal_plot_data_prep(y_pred, y_test)\n",
    "    )    \n",
    "\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'b--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare to Andrea\n",
    "\n",
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "andrea_results_ens1 = pd.read_csv('/tf/notebooks/brdd/xAI_stroke_3d/data/stroke_cimrsbinary_lossnll_wsno_augyes_cdftest_spl6_ens1.csv'\n",
    "                            ).rename(columns={\"Unnamed: 0\": \"p_idx\"})\n",
    "andrea_results_ens2 = pd.read_csv('/tf/notebooks/brdd/xAI_stroke_3d/data/stroke_cimrsbinary_lossnll_wsno_augyes_cdftest_spl6_ens2.csv'\n",
    "                            ).rename(columns={\"Unnamed: 0\": \"p_idx\"})\n",
    "andrea_results_ens3 = pd.read_csv('/tf/notebooks/brdd/xAI_stroke_3d/data/stroke_cimrsbinary_lossnll_wsno_augyes_cdftest_spl6_ens3.csv'\n",
    "                            ).rename(columns={\"Unnamed: 0\": \"p_idx\"})\n",
    "andrea_results_ens4 = pd.read_csv('/tf/notebooks/brdd/xAI_stroke_3d/data/stroke_cimrsbinary_lossnll_wsno_augyes_cdftest_spl6_ens4.csv'\n",
    "                            ).rename(columns={\"Unnamed: 0\": \"p_idx\"})\n",
    "andrea_results_ens5 = pd.read_csv('/tf/notebooks/brdd/xAI_stroke_3d/data/stroke_cimrsbinary_lossnll_wsno_augyes_cdftest_spl6_ens5.csv'\n",
    "                            ).rename(columns={\"Unnamed: 0\": \"p_idx\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOT NEEDED: same as above\n",
    "# andrea_results_trafo = pd.read_csv('/tf/notebooks/brdd/xAI_stroke_3d/data/stroke_merged_bincdf_cimrsbinary.csv')\n",
    "# andrea_results_trafo = andrea_results_trafo[\n",
    "#     (andrea_results_trafo[\"loss\"] == \"nll\") &\n",
    "#     (andrea_results_trafo[\"type\"] == \"test\") &\n",
    "#     (andrea_results_trafo[\"spl\"] == 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "andrea_calplot_dat_spl = pd.read_csv('/tf/notebooks/brdd/xAI_stroke_3d/data/bincal_splnll.csv')\n",
    "andrea_calplot_cibinary_spl = andrea_calplot_dat_spl[(andrea_calplot_dat_spl[\"mod\"] == \"cimrsbinary\") &\n",
    "                                                     (andrea_calplot_dat_spl[\"method\"] == \"trafo\") &\n",
    "                                                     (andrea_calplot_dat_spl[\"weights\"] == \"equal\")]\n",
    "andrea_calplot_cibinary_spl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "andrea_calplot_dat = pd.read_csv('/tf/notebooks/brdd/xAI_stroke_3d/data/bincal_avgnll.csv')\n",
    "andrea_calplot_cibinary_avg = andrea_calplot_dat[(andrea_calplot_dat[\"mod\"] == \"cimrsbinary\") &\n",
    "                                                 (andrea_calplot_dat[\"method\"] == \"trafo\") &\n",
    "                                                 (andrea_calplot_dat[\"weights\"] == \"equal\")]\n",
    "andrea_calplot_cibinary_avg\n",
    "# cal_plot(andrea_calplot_cibinary_avg, \"midpoint\", \"prop\", \"lwr\", \"upr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake trafo and linear averaging of results on split 6\n",
    "y_preds = np.concatenate(y_preds, axis = 1)\n",
    "y_pred_linear_avg = np.mean(y_preds, axis = 1)\n",
    "y_pred_trafo_avg = fm.sigmoid(np.mean(fm.inverse_sigmoid(y_preds), axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate calibration plots\n",
    "cal_plot_linear = fm.cal_plot_data_prep(y_pred_linear_avg, y_test)\n",
    "cal_plot_trafo = fm.cal_plot_data_prep(y_pred_trafo_avg, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(\n",
    "    {\"p_idx\": test_idx+1,\n",
    "     \"p_id\": p_id[test_idx],\n",
    "     \"mrs\": Y_mrs[test_idx],\n",
    "     \"unfavorable\": y_test,\n",
    "     \"pred_prob_1\": y_preds[:,0], \n",
    "     \"pred_prob_2\": y_preds[:,1], \n",
    "     \"pred_prob_3\": y_preds[:,2], \n",
    "     \"pred_prob_4\": y_preds[:,3], \n",
    "     \"pred_prob_5\": y_preds[:,4], \n",
    "     \"pred_prob_linear\" : y_pred_linear_avg,\n",
    "     \"pred_prob_trafo\" : y_pred_trafo_avg,\n",
    "     \"andrea_pred_prob_ens1\": 1-andrea_results_ens1[\"V2\"],\n",
    "     \"andrea_pred_prob_ens2\": 1-andrea_results_ens2[\"V2\"],\n",
    "     \"andrea_pred_prob_ens3\": 1-andrea_results_ens3[\"V2\"],\n",
    "     \"andrea_pred_prob_ens4\": 1-andrea_results_ens4[\"V2\"],\n",
    "     \"andrea_pred_prob_ens5\": 1-andrea_results_ens5[\"V2\"]\n",
    "    }\n",
    ")\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do fake trafo averaging of andreas results\n",
    "results[\"andrea_pred_prob_trafo\"] = fm.sigmoid(np.mean(fm.inverse_sigmoid(results[\n",
    "    [\"andrea_pred_prob_ens1\", \"andrea_pred_prob_ens2\", \"andrea_pred_prob_ens3\", \"andrea_pred_prob_ens4\", \"andrea_pred_prob_ens5\"]\n",
    "    ]), axis = 1))\n",
    "andrea_calplot_spl6_new = fm.cal_plot_data_prep(results[\"andrea_pred_prob_trafo\"], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "andrea_calplot_spl6_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results Andrea\n",
    "fm.calc_metrics(results[\"unfavorable\"], results[\"andrea_pred_prob_trafo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Results Python \n",
    "fm.calc_metrics(results[\"unfavorable\"], results[\"pred_prob_trafo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot AUC of Python and Andrea's results\n",
    "fpr, tpr, threshold = metrics.roc_curve(results[\"unfavorable\"], results[\"pred_prob_trafo\"])\n",
    "roc_auc = metrics.auc(fpr, tpr)  \n",
    "plt.plot(fpr, tpr, label = 'AUC Python = %0.2f' % roc_auc)\n",
    "fpr, tpr, threshold = metrics.roc_curve(results[\"unfavorable\"], results[\"andrea_pred_prob_trafo\"])\n",
    "roc_auc = metrics.auc(fpr, tpr)  \n",
    "plt.plot(fpr, tpr, label = 'AUC Andrea = %0.2f' % roc_auc)\n",
    "\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'b--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calplot of each ensemble with linear (green) and trafo (orange) averaged for split 6\n",
    "for i in range(5):\n",
    "    fm.cal_plot(cal_plot_datas[i], \n",
    "             \"predicted_probability_middle\", \"observed_proportion\",\n",
    "                        \"observed_proportion_lower\", \"observed_proportion_upper\", alpha = .35, show = False)\n",
    "fm.cal_plot(cal_plot_linear, \"predicted_probability_middle\", \"observed_proportion\",\n",
    "                        \"observed_proportion_lower\", \"observed_proportion_upper\", col = \"green\", show = False)\n",
    "# # additionaly in blue averaged over all calplots\n",
    "# fm.cal_plot(sum(cal_plot_datas)/5, \"predicted_probability_middle\", \"observed_proportion\",\n",
    "#                         \"observed_proportion_lower\", \"observed_proportion_upper\", col = \"blue\", show = False)\n",
    "fm.cal_plot(cal_plot_trafo, \"predicted_probability_middle\", \"observed_proportion\",\n",
    "                        \"observed_proportion_lower\", \"observed_proportion_upper\", col = \"orange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "andrea_calplot_cibinary_spl[\"bin_num\"] = np.array(list(range(4))*6)\n",
    "andrea_calplot_cibinary_spl_avg = andrea_calplot_cibinary_spl.groupby(\"bin_num\")[[\"prop\", \"lwr\", \"upr\", \"midpoint\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot as is in paper: per split (already trafo over each split) and averaged\n",
    "# in green averaged directly shouldn't be visible as it should be same as the blue one\n",
    "# in orange trafo averaged of own implementation of split 6\n",
    "for i in range(6):\n",
    "    fm.cal_plot(andrea_calplot_cibinary_spl[andrea_calplot_cibinary_spl[\"spl\"] == i+1], \n",
    "             \"midpoint\", \"prop\", \"lwr\", \"upr\", alpha = .35, show = False)\n",
    "fm.cal_plot(andrea_calplot_cibinary_spl_avg, \"midpoint\", \"prop\", \"lwr\", \"upr\", col = \"green\", show = False)\n",
    "fm.cal_plot(andrea_calplot_cibinary_avg, \"midpoint\", \"prop\", \"lwr\", \"upr\", show = False)\n",
    "\n",
    "fm.cal_plot(cal_plot_trafo, \"predicted_probability_middle\", \"observed_proportion\",\n",
    "                        \"observed_proportion_lower\", \"observed_proportion_upper\", col = \"orange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cal plot comparision of split 6 \n",
    "# blue: andrea original\n",
    "# green: andrea calculated numbers based on results on each ensemble, trafo averaged\n",
    "# orange: own implementation, trafo averaged\n",
    "# -------------------------------\n",
    "# green and blue should be same\n",
    "fm.cal_plot(andrea_calplot_cibinary_spl[andrea_calplot_cibinary_spl[\"spl\"] == 6], \n",
    "             \"midpoint\", \"prop\", \"lwr\", \"upr\", show = False)\n",
    "fm.cal_plot(andrea_calplot_spl6_new, \n",
    "         \"predicted_probability_middle\", \"observed_proportion\", \"observed_proportion_lower\", \"observed_proportion_upper\", \n",
    "         col = \"green\", show = False)\n",
    "fm.cal_plot(cal_plot_trafo, \n",
    "         \"predicted_probability_middle\", \"observed_proportion\", \"observed_proportion_lower\", \"observed_proportion_upper\", \n",
    "         col = \"orange\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "andrea_calplot_spl6_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "andrea_calplot_cibinary_spl[andrea_calplot_cibinary_spl[\"spl\"] == 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patient Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple scatter plots with different comparison methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.scatterplot(data=results, x=\"pred_prob_trafo\", y=\"pred_prob_linear\", hue = \"unfavorable\")\n",
    "plt.legend(loc='lower right')\n",
    "g.set(ylim=(0, 1), xlim=(0,1))\n",
    "g.plot([0,1], [0,1], \"r--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.scatterplot(data=results, x=\"pred_prob_trafo\", y=\"andrea_pred_prob_trafo\", hue = \"unfavorable\")\n",
    "plt.legend(loc='lower right')\n",
    "g.set(ylim=(0, 1), xlim=(0,1))\n",
    "g.plot([0,1], [0,1], \"r--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.scatterplot(data=results, x=\"pred_prob_2\", y=\"pred_prob_5\", hue = \"unfavorable\")\n",
    "plt.legend(loc='lower right')\n",
    "g.set(ylim=(0, 1), xlim=(0,1))\n",
    "g.plot([0,1], [0,1], \"r--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.scatterplot(data=results, x=\"andrea_pred_prob_ens2\", y=\"andrea_pred_prob_ens5\", hue = \"unfavorable\")\n",
    "plt.legend(loc='lower right')\n",
    "g.set(ylim=(0, 1), xlim=(0,1))\n",
    "g.plot([0,1], [0,1], \"r--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.scatterplot(data=results, x=\"pred_prob_1\", y=\"andrea_pred_prob_ens1\", hue = \"unfavorable\")\n",
    "plt.legend(loc='lower right')\n",
    "g.set(ylim=(0, 1), xlim=(0,1))\n",
    "g.plot([0,1], [0,1], \"r--\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
